{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-rank approximation on $\\mathcal{P}(d)$ - the space of $d$-dimensional SPD matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to get some intuition in different approaches for computing low-rank approximations for manifold-valued signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Manifolds\n",
    "using Manopt\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using Plots\n",
    "using LaTeXStrings\n",
    "using BenchmarkTools\n",
    "\n",
    "using Clustering\n",
    "using NIfTI\n",
    "\n",
    "using JLD\n",
    "using Printf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "β (generic function with 1 method)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# include(\"../../../src/functions/loss_functions/curvature_corrected_loss.jl\")\n",
    "# include(\"../../../src/functions/loss_functions/exact_loss.jl\")\n",
    "include(\"../../../src/functions/jacobi_field/beta.jl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNMF_euclidean (generic function with 1 method)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function SNMF_euclidean(X, k, init_const, max_iter)\n",
    "    # in this function X is d \\times n\n",
    "    # F is d \\times k, G is n \\times k\n",
    "    R = kmeans(X, k)\n",
    "    d = size(X)[1]\n",
    "    n = size(X)[2]\n",
    "    G_init = zeros(n, k)\n",
    "    for i=1:n\n",
    "        G_init[i,assignments(R)[i]] = 1\n",
    "    end\n",
    "    iter = 0\n",
    "    G = G_init .+ init_const\n",
    "    F = zeros(d, k)\n",
    "    while iter < max_iter\n",
    "        F = X * G * pinv(G' * G)\n",
    "        A = X' * F\n",
    "        B = F' * F\n",
    "        Apos = (abs.(A) + A) ./ 2\n",
    "        Aneg = (abs.(A) - A) ./ 2\n",
    "        Bpos = (abs.(B) + B) ./ 2\n",
    "        Bneg = (abs.(B) - B) ./ 2\n",
    "        G = G .* sqrt.((Apos + G * Bneg)./(Aneg + G * Bpos))\n",
    "        G[isnan.(G)].=0\n",
    "        iter += 1\n",
    "    end\n",
    "    return F, G\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "naive_low_rank_approximation (generic function with 1 method)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function naive_low_rank_approximation(M::AbstractManifold, q, data, k; init_const = 0.2, max_iter=50)\n",
    "    log_q_data = log.(Ref(M), Ref(q), data);\n",
    "    X_eucl = reduce(hcat, get_coordinates.(Ref(M), Ref(q), log_q_data, Ref(DefaultOrthonormalBasis())))\n",
    "    V, U = SNMF_euclidean(X_eucl, k, init_const, max_iter);\n",
    "    # Vq = get_vector.(Ref(M), Ref(q),[V[:,l] for l=1:k], Ref(DefaultOrthonormalBasis()))\n",
    "    return U, V'\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_low_rank_approximation (generic function with 1 method)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_low_rank_approximation(M::AbstractManifold, q, X, rank; ENMF_const = 0.2, ENMF_iter=50)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M)\n",
    "    r = min(n[1], d, rank)\n",
    "\n",
    "    # compute initialisation \n",
    "    U, Vq = naive_low_rank_approximation(M, q, X, r; init_const=ENMF_const, max_iter=ENMF_iter) \n",
    "    # construct linear system\n",
    "    log_q_X = log.(Ref(M), Ref(q), X)  # ∈ T_q M^n\n",
    "    \n",
    "    # construct matrix βκB\n",
    "    tensorU = repeat(reshape(U, (n[1],1,r,1)), outer=(1,d,1,d))\n",
    "    \n",
    "    tensorΨq = repeat(reshape([get_vector(M, q, Matrix(I, d, d)[:,k], DefaultOrthonormalBasis()) for k in 1:d], (1,1,1,d)), outer=(n[1],d,r,1)) \n",
    "    \n",
    "    ONB = get_basis.(Ref(M), Ref(q), DiagonalizingOrthonormalBasis.(log_q_X))\n",
    "    βκΘq = [β(ONB[j₁].data.eigenvalues[j] * (typeof(M) <: AbstractSphere ? distance(M, q, X[j₁])^2 : 1.)) .* ONB[j₁].data.vectors[j] for j₁=1:n[1], j=1:d]\n",
    "    tensorβκΘq =  repeat(reshape(βκΘq, (n[1],d,1,1)), outer=(1,1,r,d))\n",
    "    \n",
    "    tensorβκB = tensorU .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq)\n",
    "    \n",
    "    βκB = reshape(tensorβκB, (n[1] * d, r * d))\n",
    "\n",
    "    # construct matrix A\n",
    "    A = transpose(βκB) * βκB\n",
    "\n",
    "    # construct vector βκBb\n",
    "    tensorb = inner.(Ref(M), Ref(q), repeat(reshape(log_q_X, (n[1],1)), outer=(1,d)), βκΘq)\n",
    "    b = reshape(tensorb, (n[1] * d))\n",
    "    βκBb = transpose(βκB) * b\n",
    "\n",
    "    # solve linear system\n",
    "    Vₖₗ = A\\βκBb\n",
    "    tensorVₖₗ = reshape(Vₖₗ, (r, d))\n",
    "\n",
    "    # get ccRr_q\n",
    "    ccV_q = get_vector.(Ref(M), Ref(q),[tensorVₖₗ[l,:] for l=1:r], Ref(DefaultOrthonormalBasis()))\n",
    "    return ccV_q, U\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_V_update (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_V_update(M::AbstractManifold, q, X, U, rank)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M)\n",
    "    # r = min(n[1], d, rank)\n",
    "    r = min(n[1], rank)\n",
    "    \n",
    "    # construct linear system\n",
    "    log_q_X = log.(Ref(M), Ref(q), X)  # ∈ T_q M^n\n",
    "    \n",
    "    # construct matrix βκB\n",
    "    tensorU = repeat(reshape(U, (n[1],1,r,1)), outer=(1,d,1,d))\n",
    "    \n",
    "    tensorΨq = repeat(reshape([get_vector(M, q, Matrix(I, d, d)[:,k], DefaultOrthonormalBasis()) for k in 1:d], (1,1,1,d)), outer=(n[1],d,r,1)) \n",
    "    \n",
    "    ONB = get_basis.(Ref(M), Ref(q), DiagonalizingOrthonormalBasis.(log_q_X))\n",
    "    βκΘq = [β(ONB[j₁].data.eigenvalues[j] * (typeof(M) <: AbstractSphere ? distance(M, q, X[j₁])^2 : 1.)) .* ONB[j₁].data.vectors[j] for j₁=1:n[1], j=1:d]\n",
    "    tensorβκΘq =  repeat(reshape(βκΘq, (n[1],d,1,1)), outer=(1,1,r,d))\n",
    "    \n",
    "    tensorβκB = tensorU .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq)\n",
    "    \n",
    "    βκB = reshape(tensorβκB, (n[1] * d, r * d))\n",
    "\n",
    "    # construct matrix A\n",
    "    A = transpose(βκB) * βκB\n",
    "\n",
    "    # construct vector βκBb\n",
    "    tensorb = inner.(Ref(M), Ref(q), repeat(reshape(log_q_X, (n[1],1)), outer=(1,d)), βκΘq)\n",
    "    b = reshape(tensorb, (n[1] * d))\n",
    "    βκBb = transpose(βκB) * b\n",
    "\n",
    "    # solve linear system\n",
    "    Vₖₗ = A\\βκBb\n",
    "    tensorVₖₗ = reshape(Vₖₗ, (r, d))\n",
    "\n",
    "    # get ccRr_q\n",
    "    # ccV_q = get_vector.(Ref(M), Ref(q),[tensorVₖₗ[l,:] for l=1:r], Ref(DefaultOrthonormalBasis()))\n",
    "    return tensorVₖₗ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_U_update (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_U_update(M::AbstractManifold, q, X, U, V, rank; iters = 100, debug_int = 10)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M)\n",
    "    # r = min(n[1], d, rank)\n",
    "    r = min(n[1], rank)\n",
    "    # construct linear system\n",
    "    log_q_X = log.(Ref(M), Ref(q), X)  # ∈ T_q M^n\n",
    "    # Ξ_q_coords = U * V\n",
    "    # Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    # construct matrix βκB\n",
    "    tensorV = repeat(reshape(V, (1, r, 1, d)), outer=(n[1],1,d,1)) # this is j1, i1, j, i\n",
    "    tensorΨq = repeat(reshape([get_vector(M, q, Matrix(I, d, d)[:,k], DefaultOrthonormalBasis()) for k in 1:d], (1,1,1,d)), outer=(n[1],r,d,1)) # this is j1, i1, j, i\n",
    "    \n",
    "    ONB = get_basis.(Ref(M), Ref(q), DiagonalizingOrthonormalBasis.(log_q_X))\n",
    "    βκΘq = [β(ONB[j₁].data.eigenvalues[j] * (typeof(M) <: AbstractSphere ? distance(M, q, X[j₁])^2 : 1.)) .* ONB[j₁].data.vectors[j] for j₁=1:n[1], j=1:d]\n",
    "    tensorβκΘq =  repeat(reshape(βκΘq, (n[1],1,d,1)), outer=(1,r,1,d)) # this is j1, i1, j, i\n",
    "    \n",
    "    tensorβκB = tensorV .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq)\n",
    "    \n",
    "    βκB = reshape(tensorβκB, (n[1], r, d * d)) # this is j1, i1, j, i\n",
    "    # actually we want dimensions of (n[1] * r, d * d), i.e. j1, i1, j, i\n",
    "\n",
    "    # construct numerator\n",
    "    tensorb = inner.(Ref(M), Ref(q), repeat(reshape(log_q_X, (n[1],1)), outer=(1,d)), βκΘq)\n",
    "    b = reshape(repeat(reshape(tensorb, (n[1], 1, d, 1)), outer=(1, r, 1, d)), (n[1], r, d * d))\n",
    "    B = dropdims(sum(βκB .* b, dims=3),dims=3)\n",
    "    \n",
    "    Bpos = (abs.(B) + B) ./ 2\n",
    "    Bneg = (abs.(B) - B) ./ 2\n",
    "    # reshape to (n, 1, d, 1), expand to (n, r, d, d), reshape to (n, r, d * d) which is (j1, i1, j & i)\n",
    "    # then want (essentially) dot product of betakappaB and this along third dimension\n",
    "\n",
    "    # construct denominator\n",
    "    iter = 0\n",
    "    this_U = U\n",
    "    while iter < iters\n",
    "        iter += 1\n",
    "        Ξ_q_coords = this_U * V\n",
    "        Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "        tensorc = inner.(Ref(M), Ref(q), repeat(reshape(Ξ_q, (n[1], 1)), outer=(1,d)), βκΘq)\n",
    "        c = reshape(repeat(reshape(tensorc, (n[1], 1, d, 1)), outer=(1, r, 1, d)), (n[1], r, d * d))\n",
    "        C = dropdims(sum(βκB .* c, dims=3),dims=3)\n",
    "        \n",
    "        Cpos = (abs.(C) + C) ./ 2\n",
    "        Cneg = (abs.(C) - C) ./ 2\n",
    "        \n",
    "        ccU_q = this_U .* sqrt.((Bpos + Cneg)./(Bneg + Cpos))\n",
    "        ccU_q[isnan.(ccU_q)].=0\n",
    "        \n",
    "        if iter % debug_int == 0\n",
    "            Ξ_q_coords = ccU_q * V\n",
    "            Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "            CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "            ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "            @printf(\"\\tsubiter #%-4i | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(ccU_q-this_U))\n",
    "        end\n",
    "        this_U = ccU_q\n",
    "    end\n",
    "    \n",
    "#     tensorc = inner.(Ref(M), Ref(q), repeat(reshape(Ξ_q, (n[1], 1)), outer=(1,d)), βκΘq)\n",
    "#     c = reshape(repeat(reshape(tensorc, (n[1], 1, d, 1)), outer=(1, r, 1, d)), (n[1], r, d * d))\n",
    "#     C = dropdims(sum(βκB .* c, dims=3),dims=3)\n",
    "    \n",
    "#     Bpos = (abs.(B) + B) ./ 2\n",
    "#     Bneg = (abs.(B) - B) ./ 2\n",
    "#     Cpos = (abs.(C) + C) ./ 2\n",
    "#     Cneg = (abs.(C) - C) ./ 2\n",
    "    \n",
    "#     ccU_q = U .* sqrt.((Bpos + Cneg)./(Bneg + Bpos))\n",
    "#     # ccU_q = U .* (Bpos + Cneg)./(Bneg + Bpos)\n",
    "#     ccU_q[isnan.(ccU_q)].=0\n",
    "    return this_U\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_V_update_precomp_ineff (generic function with 1 method)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_V_update_precomp_ineff(M::AbstractPowerManifold, q, X, log_q_X, U, rank, βκΘq)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M.manifold)\n",
    "    D = power_dimensions(M)[1]\n",
    "    # r = min(n[1], d, rank)\n",
    "    # r = min(n[1], rank)\n",
    "    r = rank\n",
    "    \n",
    "    # construct linear system\n",
    "\n",
    "    tensorU = repeat(reshape(U, (n[1],1,r,1)), outer=(1,d*D,1,d*D))\n",
    "    # Ψ_dict = [get_vector(M.manifold, q[k], Matrix(I, d, d)[:,i], DefaultOrthonormalBasis()) for i=1:d, k=1:D]; # d by D\n",
    "    Ψ_list = [get_vector(M, q, Matrix(I, d*D, d*D)[:,i], DefaultOrthonormalBasis()) for i=1:d*D];\n",
    "    # each element of the list is a vector with D elements\n",
    "    # the list has d*D elements\n",
    "    # note that the list fixes the D index, then exhausts the d index\n",
    "    # for fixed D index, all other elements of that basis element are zero\n",
    "    # we want the tensor of \\psi_q to be n x d x r x (d * D), but maybe we hold off on collapsing down the last dimension until later?\n",
    "    # this corresponds to j1, j, i1, (i,k) in ipad notation\n",
    "    tensorΨq = repeat(reshape(Ψ_list, (1, 1, 1, d*D)), outer=(n[1], d*D, r, 1))\n",
    "    \n",
    "    # βκΘq = [β(ONB[j₁].data.bases[k].data.eigenvalues[j]) .* ONB[j₁].data.bases[k].data.vectors[j] for j₁=1:n[1], j=1:d, k=1:D];\n",
    "    # each element of fullβκΘq should be a vector with D elements\n",
    "    # each element of βκΘq is a single point in TpM\n",
    "    pt = [zeros(3,3) for i=1:D];\n",
    "    fullβκΘq = Array{Vector{Matrix{Float64}}}(undef, n[1],d*D);\n",
    "    for j₁ = 1:n[1]\n",
    "        for j=1:d\n",
    "            for k=1:D\n",
    "                this_pt = [zeros(3,3) for i=1:D];\n",
    "                this_pt[k] = βκΘq[j₁,j,k]\n",
    "                # so only kth element is nonzero\n",
    "                fullβκΘq[j₁,(k-1)*d + j] = this_pt;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    tensorβκΘq =  repeat(reshape(fullβκΘq, (n[1],d*D,1,1)), outer=(1,1,r,d*D)) # total dimensions: n, d*D, r, d*D, D with idx j1, j, i1, i\n",
    "\n",
    "    tensorβκB = tensorU .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq);\n",
    "    βκB = reshape(tensorβκB, (n[1] * d * D, r * d * D))\n",
    "    # βκB = reshape(tensorβκB, (n[1] * d, r * d))\n",
    "\n",
    "    # construct matrix A\n",
    "    A = transpose(βκB) * βκB\n",
    "    # construct vector βκBb\n",
    "    tensorb = inner.(Ref(M), Ref(q), repeat(reshape(log_q_X, (n[1],1)), outer=(1,d*D)), fullβκΘq)\n",
    "\n",
    "    b = reshape(tensorb, (n[1] * d *D))\n",
    "    βκBb = transpose(βκB) * b\n",
    "\n",
    "    # solve linear system\n",
    "    Vₖₗ = A\\βκBb\n",
    "    tensorVₖₗ = reshape(Vₖₗ, (r, d * D))\n",
    "\n",
    "    # get ccRr_q\n",
    "    # ccV_q = get_vector.(Ref(M), Ref(q),[tensorVₖₗ[l,:] for l=1:r], Ref(DefaultOrthonormalBasis()))\n",
    "    return tensorVₖₗ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_U_update_precomp_ineff (generic function with 1 method)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_U_update_precomp_ineff(M::AbstractPowerManifold, q, X, log_q_X, U, V, rank, βκΘq; iters = 100, debug_int = 10)\n",
    "    \n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M.manifold)\n",
    "    D = power_dimensions(M)[1]\n",
    "    # r = min(n[1], d, rank)\n",
    "    # r = min(n[1], rank)\n",
    "    r = rank\n",
    "    # construct linear system\n",
    "\n",
    "    # construct matrix βκB\n",
    "    tensorV = repeat(reshape(V, (1, r, 1, d*D)), outer=(n[1],1,d*D,1)) # this is j1, i1, j, i\n",
    "    Ψ_list = [get_vector(M, q, Matrix(I, d*D, d*D)[:,i], DefaultOrthonormalBasis()) for i=1:d*D];\n",
    "    tensorΨq = repeat(reshape(Ψ_list, (1, 1, 1, d*D)), outer=(n[1], r, d*D, 1))\n",
    "    \n",
    "    # ONB = get_basis.(Ref(M), Ref(q), DiagonalizingOrthonormalBasis.(log_q_X))\n",
    "    # βκΘq = [β(ONB[j₁].data.bases[k].data.eigenvalues[j]) .* ONB[j₁].data.bases[k].data.vectors[j] for j₁=1:n[1], j=1:d, k=1:D];\n",
    "    # each element of fullβκΘq should be a vector with D elements\n",
    "    # each element of βκΘq is a single point in TpM\n",
    "    # tensorβκΘq =  repeat(reshape(βκΘq, (n[1],1,d,1)), outer=(1,r,1,d)) # this is j1, i1, j, i\n",
    "    \n",
    "    pt = [zeros(3,3) for i=1:D];\n",
    "    fullβκΘq = Array{Vector{Matrix{Float64}}}(undef, n[1],d*D);\n",
    "    for j₁ = 1:n[1]\n",
    "        for j=1:d\n",
    "            for k=1:D\n",
    "                this_pt = [zeros(3,3) for i=1:D];\n",
    "                this_pt[k] = βκΘq[j₁,j,k]\n",
    "                # so only kth element is nonzero\n",
    "                fullβκΘq[j₁,(k-1)*d + j] = this_pt;\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    tensorβκΘq =  repeat(reshape(fullβκΘq, (n[1],1,d*D,1)), outer=(1,r,1,d*D)) # total dimensions: n, d*D, r, d*D, D with idx j1, i1, j, i  \n",
    "    tensorβκB = tensorV .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq)   \n",
    "    βκB = reshape(tensorβκB, (n[1], r, d*D * d*D)) # this is j1, i1, j, i\n",
    "    \n",
    "    # construct numerator\n",
    "    tensorb = inner.(Ref(M), Ref(q), repeat(reshape(log_q_X, (n[1],1)), outer=(1,d*D)), fullβκΘq)\n",
    "    b = reshape(repeat(reshape(tensorb, (n[1], 1, d*D, 1)), outer=(1, r, 1, d*D)), (n[1], r, d *D* d*D))\n",
    "    \n",
    "    B = dropdims(sum(βκB .* b, dims=3),dims=3)\n",
    "    \n",
    "    Bpos = (abs.(B) + B) ./ 2\n",
    "    Bneg = (abs.(B) - B) ./ 2\n",
    "    # reshape to (n, 1, d, 1), expand to (n, r, d, d), reshape to (n, r, d * d) which is (j1, i1, j & i)\n",
    "    # then want (essentially) dot product of betakappaB and this along third dimension\n",
    "\n",
    "    # construct denominator\n",
    "    iter = 0\n",
    "    this_U = U\n",
    "    while iter < iters\n",
    "        iter += 1\n",
    "        Ξ_q_coords = this_U * V\n",
    "        Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "        tensorc = inner.(Ref(M), Ref(q), repeat(reshape(Ξ_q, (n[1], 1)), outer=(1,d*D)), fullβκΘq)\n",
    "        c = reshape(repeat(reshape(tensorc, (n[1], 1, d*D, 1)), outer=(1, r, 1, d*D)), (n[1], r, d * D*d*D))\n",
    "        C = dropdims(sum(βκB .* c, dims=3),dims=3)\n",
    "        \n",
    "        Cpos = (abs.(C) + C) ./ 2\n",
    "        Cneg = (abs.(C) - C) ./ 2\n",
    "        \n",
    "        ccU_q = this_U .* sqrt.((Bpos + Cneg)./(Bneg + Cpos))\n",
    "        ccU_q[isnan.(ccU_q)].=0\n",
    "        \n",
    "        if iter % debug_int == 0\n",
    "            Ξ_q_coords = ccU_q * V\n",
    "            Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "            CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "            ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "            @printf(\"\\tsubiter #%-4i | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(ccU_q-this_U))\n",
    "        end\n",
    "        this_U = ccU_q\n",
    "    end\n",
    "\n",
    "    return this_U\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_V_update_precomp (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_V_update_precomp(M::AbstractPowerManifold, q, X, log_q_X, U, rank, βκΘq, tensorβκΘq, tensorΨq)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M.manifold)\n",
    "    D = power_dimensions(M)[1]\n",
    "    # r = min(n[1], d, rank)\n",
    "    # r = min(n[1], rank)\n",
    "    r = rank\n",
    "    \n",
    "    # construct linear system\n",
    "\n",
    "    tensorU = repeat(reshape(U, (n[1],1,r,1,1)), outer=(1,d,1,d,D))\n",
    "    # Ψ_mat = [get_vector(M, q, Matrix(I, d*D, d*D)[:,(k-1)*d + j], DefaultOrthonormalBasis())[k] for j=1:d, k=1:D];\n",
    "    # tensorΨq = repeat(reshape(Ψ_mat, (1, 1, d,D)), outer=(n[1], d, 1,1));\n",
    "\n",
    "    # tensorβκΘq = repeat(reshape(βκΘq,(n[1],d,1,D)), outer=(1,1,d,1));\n",
    "\n",
    "    sΨq = eachslice(tensorΨq,dims=4);\n",
    "    sβκΘq = eachslice(tensorβκΘq,dims=4);\n",
    "    pdts = reduce((x,y) -> cat(x,y,dims=4), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), sΨq, sβκΘq, q));\n",
    "\n",
    "    tensorβκB = tensorU .* repeat(reshape(pdts,(n[1],d,1,d,D)),outer=(1,1,r,1,1));\n",
    "\n",
    "    tensorβκB_exp = reshape(tensorβκB,(n[1],d,1,r,d,D));\n",
    "    tensorβκB_alt = zeros(n[1],d,D,r,d,D);\n",
    "    for k=1:D\n",
    "        tensorβκB_alt[:,:,k,:,:,k] = @view tensorβκB_exp[:,:,1,:,:,k];\n",
    "    end\n",
    "\n",
    "    βκB = reshape(tensorβκB_alt,(n[1]*d*D,r*d*D));\n",
    "\n",
    "    A = transpose(βκB) * βκB;\n",
    "\n",
    "    log_q_X_expanded = [log_q_X[j₁][k] for j₁=1:n[1],k=1:D];\n",
    "    log_q_X_tensor = repeat(reshape(log_q_X_expanded, (n[1],1,D)),outer=(1,d,1));\n",
    "    slogX = eachslice(log_q_X_tensor,dims=3);\n",
    "    sβκΘq_forlog = eachslice(βκΘq,dims=3);\n",
    "    tensorb_pre = reduce((x,y) -> cat(x,y,dims=3), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), slogX, sβκΘq_forlog, q));\n",
    "    b = reshape(tensorb_pre,(n[1] * d * D));\n",
    "    βκBb = transpose(βκB) * b;\n",
    "\n",
    "    # solve linear system\n",
    "    Vₖₗ = A\\βκBb\n",
    "    tensorVₖₗ = reshape(Vₖₗ, (r, d * D));\n",
    "    return tensorVₖₗ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_V_update_precomp! (generic function with 1 method)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_V_update_precomp!(tensorU, M::AbstractPowerManifold, q, X, log_q_X_tensor, U, rank, βκΘq, tensorβκΘq, tensorΨq)\n",
    "    # U comes in n[1] by r\n",
    "    # tensorU is n[1], d, r, d, D\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M.manifold)\n",
    "    D = power_dimensions(M)[1]\n",
    "    # r = min(n[1], d, rank)\n",
    "    # r = min(n[1], rank)\n",
    "    r = rank\n",
    "    \n",
    "    # construct linear system\n",
    "\n",
    "    # tensorU = repeat(reshape(U, (n[1],1,r,1,1)), outer=(1,d,1,d,D))\n",
    "    # loop through dimension 2 of U, then 1, and fill with repeat?\n",
    "    for col=1:r\n",
    "        for row=1:n[1]\n",
    "            tensorU[row,:,col,:,:].=view(U,row,col)\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    # Ψ_mat = [get_vector(M, q, Matrix(I, d*D, d*D)[:,(k-1)*d + j], DefaultOrthonormalBasis())[k] for j=1:d, k=1:D];\n",
    "    # tensorΨq = repeat(reshape(Ψ_mat, (1, 1, d,D)), outer=(n[1], d, 1,1));\n",
    "\n",
    "    # tensorβκΘq = repeat(reshape(βκΘq,(n[1],d,1,D)), outer=(1,1,d,1));\n",
    "\n",
    "    sΨq = eachslice(tensorΨq,dims=4);\n",
    "    sβκΘq = eachslice(tensorβκΘq,dims=4);\n",
    "    pdts = reduce((x,y) -> cat(x,y,dims=4), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), sΨq, sβκΘq, q));\n",
    "\n",
    "    tensorβκB = tensorU .* repeat(reshape(pdts,(n[1],d,1,d,D)),outer=(1,1,r,1,1));\n",
    "\n",
    "    tensorβκB_exp = reshape(tensorβκB,(n[1],d,1,r,d,D));\n",
    "    tensorβκB_alt = zeros(n[1],d,D,r,d,D);\n",
    "    for k=1:D\n",
    "        tensorβκB_alt[:,:,k,:,:,k] .= @view tensorβκB_exp[:,:,1,:,:,k];\n",
    "    end\n",
    "\n",
    "    βκB = reshape(tensorβκB_alt,(n[1]*d*D,r*d*D));\n",
    "\n",
    "    A = transpose(βκB) * βκB;\n",
    "\n",
    "    # log_q_X_expanded = [log_q_X[j₁][k] for j₁=1:n[1],k=1:D];\n",
    "    # log_q_X_tensor = repeat(reshape(log_q_X_expanded, (n[1],1,D)),outer=(1,d,1));\n",
    "    \n",
    "    slogX = eachslice(log_q_X_tensor,dims=3);\n",
    "    sβκΘq_forlog = eachslice(βκΘq,dims=3);\n",
    "    tensorb_pre = reduce((x,y) -> cat(x,y,dims=3), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), slogX, sβκΘq_forlog, q));\n",
    "    b = reshape(tensorb_pre,(n[1] * d * D));\n",
    "    βκBb = transpose(βκB) * b;\n",
    "\n",
    "    # solve linear system\n",
    "    Vₖₗ = A\\βκBb # vector of length r * d * D\n",
    "    tensorVₖₗ = reshape(Vₖₗ, (r, d * D));\n",
    "    return tensorVₖₗ\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_U_update_precomp (generic function with 1 method)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_U_update_precomp(M::AbstractPowerManifold, q, X, log_q_X, U, V, \n",
    "        rank, βκΘq, tensorβκΘq, tensorΨq; iters = 100, debug_int = 10)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M.manifold)\n",
    "    D = power_dimensions(M)[1]\n",
    "    # r = min(n[1], rank)\n",
    "    r = rank\n",
    "    # construct linear system\n",
    "\n",
    "    # construct matrix βκB\n",
    "    tensorV = repeat(reshape(V, (1,r,1,d,D)), outer=(n[1],1,d,1,1)); #n, d, r, d, D\n",
    "    # Ψ_mat = [get_vector(M, q, Matrix(I, d*D, d*D)[:,(k-1)*d + j], DefaultOrthonormalBasis())[k] for j=1:d, k=1:D];\n",
    "    # tensorΨq = repeat(reshape(Ψ_mat, (1, 1, d,D)), outer=(n[1], d, 1,1));\n",
    "\n",
    "    # tensorβκΘq = repeat(reshape(βκΘq,(n[1],d,1,D)), outer=(1,1,d,1));\n",
    "\n",
    "    \n",
    "    sΨq = eachslice(tensorΨq,dims=4);\n",
    "    sβκΘq = eachslice(tensorβκΘq,dims=4);\n",
    "    pdts = reduce((x,y) -> cat(x,y,dims=4), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), sΨq, sβκΘq, q));\n",
    "\n",
    "    tensorβκB = tensorV .* repeat(reshape(pdts,(n[1],1,d,d,D)),outer=(1,r,1,1,1));\n",
    "\n",
    "    βκB = reshape(tensorβκB,(n[1],r,d*d*D));\n",
    "    \n",
    "    # tensorβκB = tensorV .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq)   \n",
    "    # βκB = reshape(tensorβκB, (n[1], r, d*D * d*D)) # this is j1, i1, j, i\n",
    "    \n",
    "    # construct numerator\n",
    "    # log_q_X_expanded = [log_q_X[j₁][k] for j₁=1:n[1],k=1:D];\n",
    "    # log_q_X_tensor = repeat(reshape(log_q_X_expanded, (n[1],1,D)),outer=(1,d,1));\n",
    "    log_q_X_tensor = repeat(reshape([log_q_X[j₁][k] for j₁=1:n[1],k=1:D], (n[1],1,D)),outer=(1,d,1));\n",
    "    slogX = eachslice(log_q_X_tensor,dims=3);\n",
    "    sβκΘq_forlog = eachslice(βκΘq,dims=3);\n",
    "    tensorb_pre = reduce((x,y) -> cat(x,y,dims=3), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), slogX, sβκΘq_forlog, q));\n",
    "    b = reshape(repeat(reshape(tensorb_pre,(n[1], 1, d, 1, D)), outer=(1,r,1,d,1)),(n[1],r,d*d*D));\n",
    "\n",
    "    B = dropdims(sum(βκB .* b, dims=3),dims=3);\n",
    "    \n",
    "    Bpos = (abs.(B) .+ B) ./ 2\n",
    "    Bneg = (abs.(B) .- B) ./ 2\n",
    "    # reshape to (n, 1, d, 1), expand to (n, r, d, d), reshape to (n, r, d * d) which is (j1, i1, j & i)\n",
    "    # then want (essentially) dot product of betakappaB and this along third dimension\n",
    "\n",
    "    # construct denominator\n",
    "    iter = 0\n",
    "    this_U = U\n",
    "    Ξ_q_coords = this_U * V\n",
    "    Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    Cpos = similar(Bpos);\n",
    "    Cneg = similar(Bneg);\n",
    "    ccU_q = similar(this_U);\n",
    "    while iter < iters\n",
    "        iter += 1\n",
    "        # Ξ_q_coords = this_U * V\n",
    "        # Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "        # Ξ_q_expanded = [Ξ_q[j₁][k] for j₁=1:n[1],k=1:D];\n",
    "        # Ξ_q_tensor = repeat(reshape(Ξ_q_expanded, (n[1],1,D)),outer=(1,d,1));\n",
    "        Ξ_q_tensor = repeat(reshape([Ξ_q[j₁][k] for j₁=1:n[1],k=1:D], (n[1],1,D)),outer=(1,d,1));\n",
    "        sΞ_q = eachslice(Ξ_q_tensor,dims=3);\n",
    "        sβκΘq_forlog = eachslice(βκΘq,dims=3);\n",
    "        tensorc_pre = reduce((x,y) -> cat(x,y,dims=3), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), sΞ_q, sβκΘq_forlog, q));\n",
    "        # c = reshape(repeat(reshape(tensorc_pre, (n[1], 1, d, 1, D)), outer=(1, r, 1, d, 1)), (n[1], r, d*d*D))\n",
    "        # C = dropdims(sum(βκB .* c, dims=3),dims=3);\n",
    "        C = dropdims(sum(βκB .* reshape(repeat(reshape(tensorc_pre, (n[1], 1, d, 1, D)), outer=(1, r, 1, d, 1)), (n[1], r, d*d*D)), dims=3),dims=3);\n",
    "        \n",
    "        Cpos .= (abs.(C) .+ C) ./ 2\n",
    "        Cneg .= (abs.(C) .- C) ./ 2\n",
    "        \n",
    "        ccU_q .= this_U .* sqrt.((Bpos .+ Cneg)./(Bneg .+ Cpos))\n",
    "        ccU_q[isnan.(ccU_q)].=0\n",
    "        \n",
    "        Ξ_q_coords = ccU_q * V\n",
    "        Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "        if iter % debug_int == 0\n",
    "            # Ξ_q_coords = ccU_q * V\n",
    "            # Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "            CC_loss = curvature_corrected_loss_fromlog(M, q, log_q_X, Ξ_q)\n",
    "            ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "            @printf(\"\\tsubiter #%-4i | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(ccU_q-this_U))\n",
    "        end\n",
    "        this_U = ccU_q\n",
    "        \n",
    "    end\n",
    "\n",
    "    return this_U\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_U_update_precomp! (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_U_update_precomp!(tensorV, M::AbstractPowerManifold, q, X, log_q_X, log_q_X_tensor, U, V, \n",
    "        rank, βκΘq, tensorβκΘq, tensorΨq; iters = 100, debug_int = 10)\n",
    "    # V is r by (d * D)\n",
    "    n = size(X)\n",
    "    d = manifold_dimension(M.manifold)\n",
    "    D = power_dimensions(M)[1]\n",
    "    # r = min(n[1], rank)\n",
    "    r = rank\n",
    "    # construct linear system\n",
    "\n",
    "    # construct matrix βκB\n",
    "    # tensorV = repeat(reshape(V, (1,r,1,d,D)), outer=(n[1],1,d,1,1)); #n, r, d, d, D\n",
    "    V_reshape = reshape(V, (r,d,D));\n",
    "    for i1=1:r\n",
    "        for i2=1:d\n",
    "            for i3=1:D\n",
    "                tensorV[:,i1,:,i2,i3].=view(V_reshape,i1,i2,i3);\n",
    "            end\n",
    "        end\n",
    "    end   \n",
    "    # Ψ_mat = [get_vector(M, q, Matrix(I, d*D, d*D)[:,(k-1)*d + j], DefaultOrthonormalBasis())[k] for j=1:d, k=1:D];\n",
    "    # tensorΨq = repeat(reshape(Ψ_mat, (1, 1, d,D)), outer=(n[1], d, 1,1));\n",
    "\n",
    "    # tensorβκΘq = repeat(reshape(βκΘq,(n[1],d,1,D)), outer=(1,1,d,1));\n",
    "\n",
    "    \n",
    "    sΨq = eachslice(tensorΨq,dims=4);\n",
    "    sβκΘq = eachslice(tensorβκΘq,dims=4);\n",
    "    pdts = reduce((x,y) -> cat(x,y,dims=4), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), sΨq, sβκΘq, q));\n",
    "\n",
    "    tensorβκB = tensorV .* repeat(reshape(pdts,(n[1],1,d,d,D)),outer=(1,r,1,1,1));\n",
    "\n",
    "    βκB = reshape(tensorβκB,(n[1],r,d*d*D));\n",
    "    \n",
    "    # tensorβκB = tensorV .* inner.(Ref(M), Ref(q), tensorΨq, tensorβκΘq)   \n",
    "    # βκB = reshape(tensorβκB, (n[1], r, d*D * d*D)) # this is j1, i1, j, i\n",
    "    \n",
    "    # construct numerator\n",
    "    # log_q_X_expanded = [log_q_X[j₁][k] for j₁=1:n[1],k=1:D];\n",
    "    # log_q_X_tensor = repeat(reshape(log_q_X_expanded, (n[1],1,D)),outer=(1,d,1));\n",
    "    # log_q_X_tensor = repeat(reshape([log_q_X[j₁][k] for j₁=1:n[1],k=1:D], (n[1],1,D)),outer=(1,d,1));\n",
    "    slogX = eachslice(log_q_X_tensor,dims=3);\n",
    "    sβκΘq_forlog = eachslice(βκΘq,dims=3);\n",
    "    tensorb_pre = reduce((x,y) -> cat(x,y,dims=3), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), slogX, sβκΘq_forlog, q));\n",
    "    b = reshape(repeat(reshape(tensorb_pre,(n[1], 1, d, 1, D)), outer=(1,r,1,d,1)),(n[1],r,d*d*D));\n",
    "\n",
    "    B = dropdims(sum(βκB .* b, dims=3),dims=3);\n",
    "    \n",
    "    Bpos = (abs.(B) .+ B) ./ 2\n",
    "    Bneg = (abs.(B) .- B) ./ 2\n",
    "    # reshape to (n, 1, d, 1), expand to (n, r, d, d), reshape to (n, r, d * d) which is (j1, i1, j & i)\n",
    "    # then want (essentially) dot product of betakappaB and this along third dimension\n",
    "\n",
    "    # construct denominator\n",
    "    iter = 0\n",
    "    this_U = U\n",
    "    Ξ_q_coords = this_U * V\n",
    "    Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    Cpos = similar(Bpos);\n",
    "    Cneg = similar(Bneg);\n",
    "    ccU_q = similar(this_U);\n",
    "    while iter < iters\n",
    "        iter += 1\n",
    "        # Ξ_q_coords = this_U * V\n",
    "        # Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "        # Ξ_q_expanded = [Ξ_q[j₁][k] for j₁=1:n[1],k=1:D];\n",
    "        # Ξ_q_tensor = repeat(reshape(Ξ_q_expanded, (n[1],1,D)),outer=(1,d,1));\n",
    "        Ξ_q_tensor = repeat(reshape([Ξ_q[j₁][k] for j₁=1:n[1],k=1:D], (n[1],1,D)),outer=(1,d,1));\n",
    "        sΞ_q = eachslice(Ξ_q_tensor,dims=3);\n",
    "        sβκΘq_forlog = eachslice(βκΘq,dims=3);\n",
    "        tensorc_pre = reduce((x,y) -> cat(x,y,dims=3), map((x,y,z) -> inner.(Ref(M.manifold),Ref(z), x, y), sΞ_q, sβκΘq_forlog, q));\n",
    "        # c = reshape(repeat(reshape(tensorc_pre, (n[1], 1, d, 1, D)), outer=(1, r, 1, d, 1)), (n[1], r, d*d*D))\n",
    "        # C = dropdims(sum(βκB .* c, dims=3),dims=3);\n",
    "        C = dropdims(sum(βκB .* reshape(repeat(reshape(tensorc_pre, (n[1], 1, d, 1, D)), outer=(1, r, 1, d, 1)), (n[1], r, d*d*D)), dims=3),dims=3);\n",
    "        \n",
    "        Cpos .= (abs.(C) .+ C) ./ 2\n",
    "        Cneg .= (abs.(C) .- C) ./ 2\n",
    "        \n",
    "        ccU_q .= this_U .* sqrt.((Bpos .+ Cneg)./(Bneg .+ Cpos))\n",
    "        ccU_q[isnan.(ccU_q)].=0\n",
    "        \n",
    "        Ξ_q_coords = ccU_q * V\n",
    "        Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "        if iter % debug_int == 0\n",
    "            # Ξ_q_coords = ccU_q * V\n",
    "            # Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "            CC_loss = curvature_corrected_loss_fromlog(M, q, log_q_X, Ξ_q)\n",
    "            ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "            @printf(\"\\tsubiter #%-4i | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(ccU_q-this_U))\n",
    "        end\n",
    "        this_U = ccU_q\n",
    "        \n",
    "    end\n",
    "\n",
    "    return this_U\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exact_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function exact_loss(M::AbstractManifold, q, X, Ξ)\n",
    "    log_q_X = log.(Ref(M), Ref(q), X)  # ∈ T_q M^n\n",
    "    ref_distance = sum(norm.(Ref(M), Ref(q), log_q_X).^2)\n",
    "\n",
    "    exp_q_Ξ =   exp.(Ref(M), Ref(q), Ξ)\n",
    "    return sum(distance.(Ref(M), X, exp_q_Ξ).^2) / ref_distance\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_loss(M::AbstractManifold, q, X, Ξ)\n",
    "    n = size(X)\n",
    "    # d = manifold_dimension(M)\n",
    "    # compute log\n",
    "    log_q_X = log.(Ref(M), Ref(q), X)  # ∈ T_q M^n\n",
    "    ref_distance = sum(norm.(Ref(M), Ref(q), log_q_X).^2)\n",
    "    if typeof(M) <: PowerManifold\n",
    "        D = power_dimensions(M)[1]\n",
    "        d = manifold_dimension(M.manifold)\n",
    "    else\n",
    "        d = manifold_dimension(M)\n",
    "    end\n",
    "    # compute directions\n",
    "    I = CartesianIndices(n)\n",
    "    loss = 0.\n",
    "    for i in I\n",
    "        if typeof(M) <: PowerManifold\n",
    "            ONBᵢ = get_basis(M, q, DiagonalizingOrthonormalBasis(log_q_X[i]))\n",
    "            for k in 1:D\n",
    "                θₖ = ONBᵢ.data.bases[k].data.vectors\n",
    "                κₖ = ONBᵢ.data.bases[k].data.eigenvalues\n",
    "                # compute loss\n",
    "                loss += sum([β(κₖ[j])^2 * inner(M.manifold, q[k], Ξ[i][k] - log_q_X[i][k], Θₖ[j])^2 for j=1:d])\n",
    "            end\n",
    "        else\n",
    "            ONBᵢ = get_basis(M, q, DiagonalizingOrthonormalBasis(log_q_X[i]))\n",
    "            Θᵢ = ONBᵢ.data.vectors\n",
    "            κᵢ = ONBᵢ.data.eigenvalues\n",
    "\n",
    "            # if typeof(M) <: AbstractSphere # bug in Manifolds.jl\n",
    "            #     κᵢ .*= distance(M, q, X[i])^2\n",
    "            # end\n",
    "            # compute loss\n",
    "            loss += sum([β(κᵢ[j])^2 * inner(M, q, Ξ[i] - log_q_X[i], Θᵢ[j])^2 for j=1:d])\n",
    "        end\n",
    "        \n",
    "    \n",
    "    end\n",
    "    return loss/ref_distance\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_loss_fromlog (generic function with 1 method)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_loss_fromlog(M::AbstractManifold, q, log_q_X, Ξ)\n",
    "    n = size(log_q_X)\n",
    "    # d = manifold_dimension(M)\n",
    "    ref_distance = sum(norm.(Ref(M), Ref(q), log_q_X).^2)\n",
    "    if typeof(M) <: PowerManifold\n",
    "        D = power_dimensions(M)[1]\n",
    "        d = manifold_dimension(M.manifold)\n",
    "    else\n",
    "        d = manifold_dimension(M)\n",
    "    end   \n",
    "    # compute directions\n",
    "    I = CartesianIndices(n)\n",
    "    loss = 0.\n",
    "    for i in I\n",
    "        if typeof(M) <: PowerManifold\n",
    "            ONBᵢ = get_basis(M, q, DiagonalizingOrthonormalBasis(log_q_X[i]))\n",
    "            for k=1:D\n",
    "                θₖ = ONBᵢ.data.bases[k].data.vectors\n",
    "                κₖ = ONBᵢ.data.bases[k].data.eigenvalues\n",
    "                # compute loss\n",
    "                loss += sum([β(κₖ[j])^2 * inner(M.manifold, q[k], Ξ[i][k] - log_q_X[i][k], θₖ[j])^2 for j=1:d])\n",
    "            end\n",
    "        else\n",
    "            ONBᵢ = get_basis(M, q, DiagonalizingOrthonormalBasis(log_q_X[i]))\n",
    "            Θᵢ = ONBᵢ.data.vectors\n",
    "            κᵢ = ONBᵢ.data.eigenvalues\n",
    "\n",
    "            # if typeof(M) <: AbstractSphere # bug in Manifolds.jl\n",
    "            #     κᵢ .*= distance(M, q, X[i])^2\n",
    "            # end\n",
    "            # compute loss\n",
    "            loss += sum([β(κᵢ[j])^2 * inner(M, q, Ξ[i] - log_q_X[i], Θᵢ[j])^2 for j=1:d])\n",
    "        end\n",
    "        \n",
    "        \n",
    "    end\n",
    "    return loss/ref_distance\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_sNMF (generic function with 1 method)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_sNMF(M::AbstractManifold, q, X, rank; ENMF_const = 0.2, ENMF_iter = 50, max_iter=50, debug_freq=10, \n",
    "        init_type = \"eNMF\", first_factor = \"V\", max_U_iter = 100, U_debug=10)\n",
    "    n = size(X)\n",
    "    # initialize\n",
    "    if init_type == \"eNMF\"\n",
    "        U₀, V₀ = naive_low_rank_approximation(M, q, X, rank; init_const=ENMF_const, max_iter=ENMF_iter)\n",
    "    elseif init_type == \"kmeans\"\n",
    "        log_q_X = log.(Ref(M), Ref(q), X)\n",
    "        X_eucl = reduce(hcat, get_coordinates.(Ref(M), Ref(q), log_q_X, Ref(DefaultOrthonormalBasis())))\n",
    "        R = kmeans(X_eucl, rank)\n",
    "        d = size(X_eucl)[1]\n",
    "        this_n = size(X_eucl)[2]\n",
    "        G_init = zeros(this_n, rank)\n",
    "        for i=1:this_n\n",
    "            G_init[i,assignments(R)[i]] = 1\n",
    "        end\n",
    "        V₀ = R.centers' # k \\times d\n",
    "        replace!(x -> x == 0 ? ENMF_const : x, G_init)\n",
    "        U₀ = G_init ./ sum(G_init;dims=2)\n",
    "    elseif init_type == \"rand\"\n",
    "        G_init = rand(Float64, (n[1],rank)); # TODO make this general\n",
    "        U₀ = G_init ./ sum(G_init;dims=2)\n",
    "        d=manifold_dimension(M);\n",
    "        V₀ = randn(Float64, (rank, d)); # k \\times d\n",
    "        \n",
    "    else\n",
    "       throw(ArgumentError(\"init_type must be eNMF, kmeans, or rand\"))\n",
    "    end\n",
    "    println(\"computed initialization\")\n",
    "    iter = 0\n",
    "    Uₖ = copy(U₀)\n",
    "    Vₖ = copy(V₀)\n",
    "    Ξ_q_coords = Uₖ * Vₖ\n",
    "    Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "    ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "    @printf(\"iter #0        | CCL: %.15f | exact loss: %.15f\\n\", CC_loss, ex_loss)\n",
    "    # Ξ_q = []\n",
    "    while iter < max_iter\n",
    "        iter += 1\n",
    "        Uprev = Uₖ\n",
    "        Vprev = Vₖ\n",
    "        U_iter = 0\n",
    "        if first_factor == \"V\" \n",
    "            Vₖ = curvature_corrected_V_update(M, q, X, Uₖ, rank)\n",
    "            if iter % debug_freq == 0\n",
    "                Ξ_q_coords = Uₖ * Vₖ\n",
    "                Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "                CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "                ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "                @printf(\"iter #%-4i (V) | CCL: %.15f | exact loss: %.15f | change (V): %.5f\\n\", iter, CC_loss, ex_loss, norm(Vₖ-Vprev))\n",
    "                # println(\"iter #$(iter) (V) | CCL: $(CC_loss) | exact loss: $(ex_loss)\")\n",
    "            end\n",
    "\n",
    "            Uprev=Uₖ\n",
    "            Uₖ = curvature_corrected_U_update(M, q, X, Uprev, Vₖ, rank;iters = max_U_iter,debug_int=U_debug)\n",
    "            if iter % debug_freq == 0\n",
    "                Ξ_q_coords = Uₖ * Vₖ\n",
    "                Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "                CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "                ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "                @printf(\"iter #%-4i (U) | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(Uₖ-Uprev))\n",
    "                # println(\"iter #$(iter) (U) | CCL: $(CC_loss) | exact loss: $(ex_loss)\")\n",
    "            end\n",
    "            # U_iter += 1\n",
    "\n",
    "        else\n",
    "            Uₖ = curvature_corrected_U_update(M, q, X, Uprev, Vₖ, rank)\n",
    "            if iter % debug_freq == 0\n",
    "                Ξ_q_coords = Uₖ * Vₖ\n",
    "                Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "                CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "                ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "                @printf(\"iter #%-4i (U) | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(Uₖ-Uprev))\n",
    "                # println(\"iter #$(iter) (U) | CCL: $(CC_loss) | exact loss: $(ex_loss)\")\n",
    "            end\n",
    "            Vₖ = curvature_corrected_V_update(M, q, X, Uₖ, rank)\n",
    "            if iter % debug_freq == 0\n",
    "                Ξ_q_coords = Uₖ * Vₖ\n",
    "                Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "                CC_loss = curvature_corrected_loss(M, q, X, Ξ_q)\n",
    "                ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "                @printf(\"iter #%-4i (V) | CCL: %.15f | exact loss: %.15f | change (V): %.5f\\n\", iter, CC_loss, ex_loss, norm(Vₖ-Vprev))\n",
    "                # println(\"iter #$(iter) (V) | CCL: $(CC_loss) | exact loss: $(ex_loss)\")\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if init_type == \"kmeans\"\n",
    "        U₀ = G_init;\n",
    "    end\n",
    "    return Uₖ, Vₖ, Ξ_q, U₀, V₀\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "curvature_corrected_sNMF_precomp (generic function with 1 method)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function curvature_corrected_sNMF_precomp(M::AbstractPowerManifold, q, X, log_q_X, rank; ENMF_const = 0.2, ENMF_iter = 50, max_iter=50, \n",
    "        debug_freq=10, init_type = \"eNMF\", max_U_iter = 100, U_debug=10)\n",
    "    n = size(X)\n",
    "    # initialize\n",
    "    if init_type == \"eNMF\"\n",
    "        U₀, V₀ = naive_low_rank_approximation(M, q, X, rank; init_const=ENMF_const, max_iter=ENMF_iter)\n",
    "    elseif init_type == \"kmeans\"\n",
    "        # log_q_X = log.(Ref(M), Ref(q), X)\n",
    "        X_eucl = reduce(hcat, get_coordinates.(Ref(M), Ref(q), log_q_X, Ref(DefaultOrthonormalBasis())))\n",
    "        R = kmeans(X_eucl, rank)\n",
    "        # d = size(X_eucl)[1]\n",
    "        this_n = size(X_eucl)[2]\n",
    "        G_init = zeros(this_n, rank)\n",
    "        for i=1:this_n\n",
    "            G_init[i,assignments(R)[i]] = 1\n",
    "        end\n",
    "        V₀ = R.centers' # k \\times d\n",
    "        replace!(x -> x == 0 ? ENMF_const : x, G_init)\n",
    "        U₀ = G_init ./ sum(G_init;dims=2)\n",
    "    elseif init_type == \"rand\"\n",
    "        G_init = rand(Float64, (n[1],rank)); # TODO make this general\n",
    "        U₀ = G_init ./ sum(G_init;dims=2)\n",
    "        d=manifold_dimension(M);\n",
    "        V₀ = randn(Float64, (rank, d)); # k \\times d\n",
    "    else\n",
    "       throw(ArgumentError(\"init_type must be eNMF, kmeans, or rand\"))\n",
    "    end\n",
    "    println(\"computed initialization\")\n",
    "    iter = 0\n",
    "    Uₖ = copy(U₀)\n",
    "    Vₖ = copy(V₀)\n",
    "    Ξ_q_coords = Uₖ * Vₖ\n",
    "    Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    CC_loss = curvature_corrected_loss_fromlog(M, q, log_q_X, Ξ_q)\n",
    "    ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "    @printf(\"iter #0        | CCL: %.15f | exact loss: %.15f\\n\", CC_loss, ex_loss)\n",
    "    # Ξ_q = []\n",
    "    ONB = get_basis.(Ref(M), Ref(q), DiagonalizingOrthonormalBasis.(log_q_X))\n",
    "    d = manifold_dimension(M.manifold);\n",
    "    D = power_dimensions(M)[1];\n",
    "\n",
    "    βκΘq = [β(ONB[j₁].data.bases[k].data.eigenvalues[j]) .* ONB[j₁].data.bases[k].data.vectors[j] for j₁=1:n[1], j=1:d, k=1:D];\n",
    "    tensorβκΘq = repeat(reshape(βκΘq,(n[1],d,1,D)), outer=(1,1,d,1));\n",
    "\n",
    "    Ψ_mat = [get_vector(M, q, Matrix(I, d*D, d*D)[:,(k-1)*d + j], DefaultOrthonormalBasis())[k] for j=1:d, k=1:D];\n",
    "    tensorΨq = repeat(reshape(Ψ_mat, (1, 1, d,D)), outer=(n[1], d, 1,1));\n",
    "    \n",
    "    tensorU = zeros(n[1],d,rank,d,D);\n",
    "    tensorV = zeros(n[1],rank,d, d, D);\n",
    "    log_q_X_tensor = repeat(reshape([log_q_X[j₁][k] for j₁=1:n[1],k=1:D], (n[1],1,D)),outer=(1,d,1));\n",
    "    while iter < max_iter\n",
    "        iter += 1\n",
    "        Uprev = Uₖ\n",
    "        Vprev = Vₖ\n",
    "\n",
    "        # Vₖ = curvature_corrected_V_update_precomp(M, q, X, log_q_X, Uₖ, rank, βκΘq, tensorβκΘq, tensorΨq)\n",
    "        Vₖ = curvature_corrected_V_update_precomp!(tensorU, M, q, X, log_q_X_tensor, Uₖ, rank, βκΘq, tensorβκΘq, tensorΨq)\n",
    "\n",
    "        if iter % debug_freq == 0\n",
    "            Ξ_q_coords = Uₖ * Vₖ\n",
    "            Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "            CC_loss = curvature_corrected_loss_fromlog(M, q, log_q_X, Ξ_q)\n",
    "            ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "            @printf(\"iter #%-4i (V) | CCL: %.15f | exact loss: %.15f | change (V): %.5f\\n\", iter, CC_loss, ex_loss, norm(Vₖ-Vprev))\n",
    "            # println(\"iter #$(iter) (V) | CCL: $(CC_loss) | exact loss: $(ex_loss)\")\n",
    "        end\n",
    "\n",
    "        Uprev=Uₖ\n",
    "        # Uₖ = curvature_corrected_U_update_precomp(M, q, X, log_q_X, Uprev, Vₖ, rank, βκΘq, tensorβκΘq, tensorΨq;iters = max_U_iter,debug_int=U_debug)\n",
    "        Uₖ = curvature_corrected_U_update_precomp!(tensorV, M, q, X, log_q_X, log_q_X_tensor, Uprev, Vₖ, rank, βκΘq, tensorβκΘq, tensorΨq;iters = max_U_iter,debug_int=U_debug)\n",
    "        if iter % debug_freq == 0\n",
    "            Ξ_q_coords = Uₖ * Vₖ\n",
    "            Ξ_q = get_vector.(Ref(M), Ref(q), [Ξ_q_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "            CC_loss = curvature_corrected_loss_fromlog(M, q, log_q_X, Ξ_q)\n",
    "            ex_loss = exact_loss(M, q, X, Ξ_q)\n",
    "            @printf(\"iter #%-4i (U) | CCL: %.15f | exact loss: %.15f | change (U): %.5f\\n\", iter, CC_loss, ex_loss, norm(Uₖ-Uprev))\n",
    "            # println(\"iter #$(iter) (U) | CCL: $(CC_loss) | exact loss: $(ex_loss)\")\n",
    "        end\n",
    "\n",
    "    end\n",
    "    if init_type == \"kmeans\"\n",
    "        U₀ = G_init;\n",
    "    end\n",
    "    return Uₖ, Vₖ, Ξ_q, U₀, V₀\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_corrected_factors (generic function with 1 method)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_corrected_factors(M::AbstractManifold, q, U, V)\n",
    "    # U is n \\times k\n",
    "    # V is k \\times d\n",
    "    K = size(U)[2]\n",
    "    V_TM = get_vector.(Ref(M), Ref(q), [V[l,:] for l=1:K], Ref(DefaultOrthonormalBasis()))\n",
    "    # proj_components = zeros(K)\n",
    "    proj_components = reduce(hcat, [[minimum([inner(M, q, V_TM[k], V_TM[l]),0])/inner(M, q, V_TM[k], V_TM[k]) for k=1:K] for l=1:K])';\n",
    "    H = U + U * proj_components\n",
    "    return H\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_label_mat (generic function with 1 method)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_label_mat(A)\n",
    "    # assuming A is n \\times k, where n is number of points and k is number of classes\n",
    "    _, idxs = findmax(A;dims=2)\n",
    "    B = zeros(size(A))\n",
    "    B[idxs] .= 1.0\n",
    "    return B\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_used_labels (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_used_labels(A)\n",
    "    idxs = findall(x -> x > 0,sum(A;dims=1))\n",
    "    cols_to_keep = [idxs[i][2] for i=1:length(idxs)]\n",
    "    clean_A = A[:,cols_to_keep]\n",
    "    return clean_A\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_f1 (generic function with 1 method)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_f1(X,Y; avg_type=\"equal\")\n",
    "    # X is n \\times k label matrix of ground truth\n",
    "    # Y is n \\times r label matrix\n",
    "    clean_X = get_used_labels(X)\n",
    "    clean_Y = get_used_labels(Y)\n",
    "    k=size(clean_X)[2]\n",
    "    r=size(clean_Y)[2]\n",
    "    inner_pdts = clean_X' * clean_Y\n",
    "    X_tot = repeat(sum(clean_X;dims=1)', outer=(1,r))\n",
    "    Y_tot = repeat(sum(clean_Y;dims=1), outer=(k,1))\n",
    "    F_mat = 2.0*inner_pdts ./ (X_tot + Y_tot);\n",
    "    F = maximum(F_mat;dims=2)\n",
    "    if avg_type==\"equal\"\n",
    "        return mean(F)\n",
    "    elseif avg_type==\"weighted\"\n",
    "        return mean(F,weights(sum(clean_X;dims=1)))\n",
    "    elseif avg_type==\"none\"\n",
    "        return F\n",
    "    else\n",
    "        throw(ArgumentError(\"avg_type must be equal, weighted, or none\"))\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_rand_idx (generic function with 1 method)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_rand_idx(X,Y)\n",
    "    # assuming X is n \\times k, Y is n \\times r, both label matrices\n",
    "    X_clean = get_used_labels(X);\n",
    "    Y_clean = get_used_labels(Y);\n",
    "    X_same_counts = X_clean * X_clean';\n",
    "    Y_same_counts = Y_clean * Y_clean';\n",
    "    N = size(X)[1]\n",
    "    same_clusters = X_same_counts .* Y_same_counts;\n",
    "    a = sum(triu(same_clusters,1))\n",
    "    b = sum(triu((ones(N,N)-X_same_counts) .* (ones(N,N) - Y_same_counts),1))\n",
    "    return (a + b)/binomial(N,2)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and construct manifold ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 218, 182)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ni_xx = niread(\"../../../data/IITmean_xx.nii.gz\") * 1e3;\n",
    "ni_yx = niread(\"../../../data/IITmean_yx.nii.gz\") * 1e3;\n",
    "ni_yy = niread(\"../../../data/IITmean_yy.nii.gz\") * 1e3;\n",
    "ni_zx = niread(\"../../../data/IITmean_zx.nii.gz\") * 1e3;\n",
    "ni_zy = niread(\"../../../data/IITmean_zy.nii.gz\") * 1e3;\n",
    "ni_zz = niread(\"../../../data/IITmean_zz.nii.gz\") * 1e3;\n",
    "size(ni_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(182, 218, 182)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1, d2, d3  = size(ni_xx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predata = [ # data ordered as [xx, yx, yy, zx, zy, zz]\n",
    "    [\n",
    "    [ni_xx[i,j,k] + 1e-5;; ni_yx[i,j,k];; ni_zx[i,j,k]]; \n",
    "    [ni_yx[i,j,k];; ni_yy[i,j,k] + 1e-5;; ni_zy[i,j,k]]; \n",
    "    [ni_zx[i,j,k];; ni_zy[i,j,k];; ni_zz[i,j,k] + 1e-5]\n",
    "    ] for i=1:d1, j=1:d2, k=1:d3];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_det = det.(predata);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum(findall(x -> x > 2e-15, all_det[:,:,25:124]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum(findall(x -> x > 2e-15, all_det[:,:,25:124]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predata_masked = predata[18:164,15:203,1:161];\n",
    "# predata_masked = predata[41:140,61:160,56];\n",
    "# predata_masked = predata[41:140,61:160,25:124];\n",
    "\n",
    "# predata_masked = predata[41:140,61:160,25:44];\n",
    "# smaller patches for testing\n",
    "# predata_masked = predata[81:100,101:120,25:44];\n",
    "\n",
    "# small center patch\n",
    "# predata_masked = predata[86:95,106:115,25:44];\n",
    "\n",
    "# used in previous experiments:\n",
    "# small corner patch\n",
    "# predata_masked = @view predata[101:110,151:160,51:100]; # used for saved data\n",
    "# predata_masked = predata[101:110,151:160,51]; # one slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_step_range (generic function with 1 method)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_step_range(start, stop, step)\n",
    "    n_steps = ((stop-start) + 1) / step;\n",
    "    this_range = [convert(Int64,start + (i-1) * step) for i=1:(n_steps+1)]\n",
    "    return this_range\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's take 4 x 4 x 4 voxels\n",
    "# first let's try the piece from the previous (approximately):\n",
    "x1 = 101;\n",
    "x2 = 112;\n",
    "y1 = 151;\n",
    "y2 = 162;\n",
    "z1 = 51;\n",
    "z2 = 102;\n",
    "step = 4;\n",
    "x_range = get_step_range(x1,x2,step);\n",
    "y_range = get_step_range(y1,y2,step);\n",
    "z_range = get_step_range(z1,z2,step);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predata_masked = [reshape(predata[x_range[i]:x_range[i+1]-1,y_range[j]:y_range[j+1]-1,z_range[k]:z_range[k+1]-1],\n",
    "        (1,:)) for i=1:length(x_range)-1,\n",
    "        j=1:length(y_range)-1,k=1:length(z_range)-1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 13)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(predata_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=vec(predata_masked);\n",
    "size(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size(data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_xx = nothing;\n",
    "ni_yx = nothing;\n",
    "ni_yy = nothing;\n",
    "ni_zx = nothing;\n",
    "ni_zy = nothing;\n",
    "ni_zz = nothing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "384"
     ]
    }
   ],
   "source": [
    "# construct data manifold\n",
    "n = size(data)[1] \n",
    "M = PowerManifold(SymmetricPositiveDefinite(3), NestedPowerRepresentation(), size(data[1])[2])\n",
    "d = manifold_dimension(M);\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64"
     ]
    }
   ],
   "source": [
    "D = power_dimensions(M)[1];\n",
    "print(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "predata_masked=nothing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predata=nothing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export slice image\n",
    "# filename = \"full_IIT_test.asy\"\n",
    "# # asymptote_export_SPD(filename, data = reshape(data, (10, 10)), scale_axes=(2, 2, 2));\n",
    "# asymptote_export_SPD(filename, data = predata_masked, scale_axes=(1, 1, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# render_asymptote(filename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"IIT_test.asy\"\n",
    "# asymptote_export_SPD(filename, data=[predata_masked[47,138,86]]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct low rank approximation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = [Matrix(I, 3, 3) .* 1e-5 for i=1:D];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q = mean(M, data)\n",
    "# q = Matrix(I, 3, 3) .* 1e-4\n",
    "log_q_data = log.(Ref(M), Ref(q), data);  # ∈ T_q P(3)^n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "offset = 0.1\n",
    "# E_iter = 50\n",
    "CC_iter = 20;\n",
    "debug_int = 1;\n",
    "U_iters = 10;\n",
    "U_debug_int = 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computing rank 20 approximation\n",
      "computed initialization\n",
      "iter #0        | CCL: 0.001255518777412 | exact loss: 0.001254790874380\n",
      "iter #1    (V) | CCL: 0.000428747619051 | exact loss: 0.000428327989921 | change (V): 75.78108\n",
      "\tsubiter #3    | CCL: 0.000393624819833 | exact loss: 0.000393211974086 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000390877039759 | exact loss: 0.000390469682492 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000388671449745 | exact loss: 0.000388269326048 | change (U): 0.00000\n",
      "iter #1    (U) | CCL: 0.000387947044276 | exact loss: 0.000387546637449 | change (U): 0.02540\n",
      "iter #2    (V) | CCL: 0.000387922411594 | exact loss: 0.000387523162908 | change (V): 0.61248\n",
      "\tsubiter #3    | CCL: 0.000385748219825 | exact loss: 0.000385354090261 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000383610567873 | exact loss: 0.000383221459169 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000381508485744 | exact loss: 0.000381124302801 | change (U): 0.00000\n",
      "iter #2    (U) | CCL: 0.000380815544968 | exact loss: 0.000380432983212 | change (U): 0.01395\n",
      "iter #3    (V) | CCL: 0.000380793160703 | exact loss: 0.000380412526954 | change (V): 0.59316\n",
      "\tsubiter #3    | CCL: 0.000378711026941 | exact loss: 0.000378335230708 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000376663507898 | exact loss: 0.000376292457206 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000374649614421 | exact loss: 0.000374283219659 | change (U): 0.00000\n",
      "iter #3    (U) | CCL: 0.000373985646391 | exact loss: 0.000373620784049 | change (U): 0.01349\n",
      "iter #4    (V) | CCL: 0.000373964162343 | exact loss: 0.000373601168667 | change (V): 0.58823\n",
      "\tsubiter #3    | CCL: 0.000371968739477 | exact loss: 0.000371610315517 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000370006216185 | exact loss: 0.000369652274831 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000368075492286 | exact loss: 0.000367725949047 | change (U): 0.00000\n",
      "iter #4    (U) | CCL: 0.000367438849586 | exact loss: 0.000367090753955 | change (U): 0.01305\n",
      "iter #5    (V) | CCL: 0.000367418042537 | exact loss: 0.000367071758056 | change (V): 0.58643\n",
      "\tsubiter #3    | CCL: 0.000365504221011 | exact loss: 0.000365162250793 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000363621750282 | exact loss: 0.000363284011954 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000361769372465 | exact loss: 0.000361435786442 | change (U): 0.00000\n",
      "iter #5    (U) | CCL: 0.000361158473269 | exact loss: 0.000360826253993 | change (U): 0.01263\n",
      "iter #6    (V) | CCL: 0.000361138149691 | exact loss: 0.000360807687507 | change (V): 0.58733\n",
      "\tsubiter #3    | CCL: 0.000359301051361 | exact loss: 0.000358974660204 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000357493911500 | exact loss: 0.000357171513608 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000355715277313 | exact loss: 0.000355396797789 | change (U): 0.00000\n",
      "iter #6    (U) | CCL: 0.000355128613352 | exact loss: 0.000354811423622 | change (U): 0.01224\n",
      "iter #7    (V) | CCL: 0.000355108609447 | exact loss: 0.000354793126451 | change (V): 0.59051\n",
      "\tsubiter #3    | CCL: 0.000353343607816 | exact loss: 0.000353031964585 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000351607318247 | exact loss: 0.000351299441510 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000349898063933 | exact loss: 0.000349593883258 | change (U): 0.00000\n",
      "iter #7    (U) | CCL: 0.000349334205950 | exact loss: 0.000349031241943 | change (U): 0.01187\n",
      "iter #8    (V) | CCL: 0.000349314383697 | exact loss: 0.000349013079816 | change (V): 0.59560\n",
      "\tsubiter #3    | CCL: 0.000347617114934 | exact loss: 0.000347319431214 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000345947446949 | exact loss: 0.000345653314482 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000344303456707 | exact loss: 0.000344012809311 | change (U): 0.00000\n",
      "iter #8    (U) | CCL: 0.000343761057235 | exact loss: 0.000343471557103 | change (U): 0.01153\n",
      "iter #9    (V) | CCL: 0.000343741300899 | exact loss: 0.000343453417943 | change (V): 0.60226\n",
      "\tsubiter #3    | CCL: 0.000342107667609 | exact loss: 0.000341823196493 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000340500648108 | exact loss: 0.000340219524160 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000338918056783 | exact loss: 0.000338640217861 | change (U): 0.00000\n",
      "iter #9    (U) | CCL: 0.000338395850813 | exact loss: 0.000338119093351 | change (U): 0.01121\n",
      "iter #10   (V) | CCL: 0.000338376063900 | exact loss: 0.000338100884141 | change (V): 0.61019\n",
      "\tsubiter #3    | CCL: 0.000336802233325 | exact loss: 0.000336530267957 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000335254143177 | exact loss: 0.000334985331637 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000333729333902 | exact loss: 0.000333463617883 | change (U): 0.00000\n",
      "iter #10   (U) | CCL: 0.000333226137947 | exact loss: 0.000332961441051 | change (U): 0.01091\n",
      "iter #11   (V) | CCL: 0.000333206240588 | exact loss: 0.000332943085164 | change (V): 0.61915\n",
      "\tsubiter #3    | CCL: 0.000331688638637 | exact loss: 0.000331428510596 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000330196007005 | exact loss: 0.000329938849763 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000328725605093 | exact loss: 0.000328471363980 | change (U): 0.00000\n",
      "iter #11   (U) | CCL: 0.000328240315064 | exact loss: 0.000327987034064 | change (U): 0.01064\n",
      "iter #12   (V) | CCL: 0.000328220241776 | exact loss: 0.000327968468989 | change (V): 0.62892\n",
      "\tsubiter #3    | CCL: 0.000326755544045 | exact loss: 0.000326506621634 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000325315139804 | exact loss: 0.000325069015029 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000323896003943 | exact loss: 0.000323652625583 | change (U): 0.00000\n",
      "iter #12   (U) | CCL: 0.000323427592167 | exact loss: 0.000323185118092 | change (U): 0.01039\n",
      "iter #13   (V) | CCL: 0.000323407289947 | exact loss: 0.000323166293522 | change (V): 0.63931\n",
      "\tsubiter #3    | CCL: 0.000321992410666 | exact loss: 0.000321754097166 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000320601231808 | exact loss: 0.000320365552200 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000319230443419 | exact loss: 0.000318997349746 | change (U): 0.00000\n",
      "iter #13   (U) | CCL: 0.000318777955081 | exact loss: 0.000318545712903 | change (U): 0.01016\n",
      "iter #14   (V) | CCL: 0.000318757381794 | exact loss: 0.000318526589121 | change (V): 0.65019\n",
      "\tsubiter #3    | CCL: 0.000317389461437 | exact loss: 0.000317161193347 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000316044723188 | exact loss: 0.000315818934219 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000314719574614 | exact loss: 0.000314496219898 | change (U): 0.00000\n",
      "iter #14   (U) | CCL: 0.000314282123843 | exact loss: 0.000314059570725 | change (U): 0.00994\n",
      "iter #15   (V) | CCL: 0.000314261246847 | exact loss: 0.000314040117238 | change (V): 0.66142\n",
      "\tsubiter #3    | CCL: 0.000312937638989 | exact loss: 0.000312718884296 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000311636761200 | exact loss: 0.000311420339391 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000310354743262 | exact loss: 0.000310140612390 | change (U): 0.00000\n",
      "iter #15   (U) | CCL: 0.000309931509016 | exact loss: 0.000309718132597 | change (U): 0.00975\n",
      "iter #16   (V) | CCL: 0.000309910303999 | exact loss: 0.000309698326988 | change (V): 0.67289\n",
      "\tsubiter #3    | CCL: 0.000308628561866 | exact loss: 0.000308418818350 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000307369156108 | exact loss: 0.000307161607341 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000306127945431 | exact loss: 0.000305922552229 | change (U): 0.00000\n",
      "iter #16   (U) | CCL: 0.000305718167327 | exact loss: 0.000305513484043 | change (U): 0.00957\n",
      "iter #17   (V) | CCL: 0.000305696617313 | exact loss: 0.000305493310999 | change (V): 0.68450\n",
      "\tsubiter #3    | CCL: 0.000304454480354 | exact loss: 0.000304253273941 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000303234337041 | exact loss: 0.000303035194927 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000302031783451 | exact loss: 0.000301834669060 | change (U): 0.00000\n",
      "iter #17   (U) | CCL: 0.000301634757618 | exact loss: 0.000301438311091 | change (U): 0.00940\n",
      "iter #18   (V) | CCL: 0.000301612852118 | exact loss: 0.000301417761562 | change (V): 0.69619\n",
      "\tsubiter #3    | CCL: 0.000300408232855 | exact loss: 0.000300215116030 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000299225308630 | exact loss: 0.000299034132933 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000298059422837 | exact loss: 0.000297870154158 | change (U): 0.00000\n",
      "iter #18   (U) | CCL: 0.000297674497882 | exact loss: 0.000297485857356 | change (U): 0.00925\n",
      "iter #19   (V) | CCL: 0.000297652232160 | exact loss: 0.000297464927851 | change (V): 0.70789\n",
      "\tsubiter #3    | CCL: 0.000296483203475 | exact loss: 0.000296297753759 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000295335609031 | exact loss: 0.000295151984161 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000294204550764 | exact loss: 0.000294022718956 | change (U): 0.00000\n",
      "iter #19   (U) | CCL: 0.000293831123881 | exact loss: 0.000293649882736 | change (U): 0.00911\n",
      "iter #20   (V) | CCL: 0.000293808498316 | exact loss: 0.000293628574697 | change (V): 0.71953\n",
      "\tsubiter #3    | CCL: 0.000292673281309 | exact loss: 0.000292495099799 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000291559269753 | exact loss: 0.000291382803319 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000290461336439 | exact loss: 0.000290286555492 | change (U): 0.00000\n",
      "iter #20   (U) | CCL: 0.000290098849706 | exact loss: 0.000289924624031 | change (U): 0.00899\n",
      "computing rank 40 approximation\n",
      "computed initialization\n",
      "iter #0        | CCL: 0.001532157897995 | exact loss: 0.001531341302401\n",
      "iter #1    (V) | CCL: 0.000203718424132 | exact loss: 0.000203489709144 | change (V): 219.97848\n",
      "\tsubiter #3    | CCL: 0.000183561705435 | exact loss: 0.000183348403182 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000179703835731 | exact loss: 0.000179504512614 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000176267747390 | exact loss: 0.000176081201065 | change (U): 0.00000\n",
      "iter #1    (U) | CCL: 0.000175159755786 | exact loss: 0.000174977223957 | change (U): 0.01443\n",
      "iter #2    (V) | CCL: 0.000175104856571 | exact loss: 0.000174924017934 | change (V): 1.84000\n",
      "\tsubiter #3    | CCL: 0.000171825131551 | exact loss: 0.000171655785893 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000168698724885 | exact loss: 0.000168539897993 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000165716174430 | exact loss: 0.000165566986382 | change (U): 0.00000\n",
      "iter #2    (U) | CCL: 0.000164752447760 | exact loss: 0.000164606291701 | change (U): 0.01027\n",
      "iter #3    (V) | CCL: 0.000164706588185 | exact loss: 0.000164562139493 | change (V): 1.69026\n",
      "\tsubiter #3    | CCL: 0.000161852218513 | exact loss: 0.000161716404586 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000159127810133 | exact loss: 0.000158999909781 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000156525078228 | exact loss: 0.000156404443164 | change (U): 0.00000\n",
      "iter #3    (U) | CCL: 0.000155683274561 | exact loss: 0.000155564927930 | change (U): 0.00957\n",
      "iter #4    (V) | CCL: 0.000155643877914 | exact loss: 0.000155527037693 | change (V): 1.57445\n",
      "\tsubiter #3    | CCL: 0.000153148905122 | exact loss: 0.000153038569588 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000150764486553 | exact loss: 0.000150660122749 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000148483192864 | exact loss: 0.000148384324419 | change (U): 0.00000\n",
      "iter #4    (U) | CCL: 0.000147744615273 | exact loss: 0.000147647480624 | change (U): 0.00895\n",
      "iter #5    (V) | CCL: 0.000147710085355 | exact loss: 0.000147614257082 | change (V): 1.48191\n",
      "\tsubiter #3    | CCL: 0.000145518928276 | exact loss: 0.000145428022904 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000143422148938 | exact loss: 0.000143335772848 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000141412997184 | exact loss: 0.000141330800610 | change (U): 0.00000\n",
      "iter #5    (U) | CCL: 0.000140761857231 | exact loss: 0.000140680981854 | change (U): 0.00841\n",
      "iter #6    (V) | CCL: 0.000140731141734 | exact loss: 0.000140651388900 | change (V): 1.40557\n",
      "\tsubiter #3    | CCL: 0.000138797151211 | exact loss: 0.000138721148205 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000136944022928 | exact loss: 0.000136871478855 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000135165580947 | exact loss: 0.000135096238763 | change (U): 0.00000\n",
      "iter #6    (U) | CCL: 0.000134588607331 | exact loss: 0.000134520279515 | change (U): 0.00794\n",
      "iter #7    (V) | CCL: 0.000134560988481 | exact loss: 0.000134493621364 | change (V): 1.34065\n",
      "\tsubiter #3    | CCL: 0.000132845110670 | exact loss: 0.000132780622849 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000131198779748 | exact loss: 0.000131136955831 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000129616325711 | exact loss: 0.000129556976328 | change (U): 0.00000\n",
      "iter #7    (U) | CCL: 0.000129102394851 | exact loss: 0.000129043831280 | change (U): 0.00751\n",
      "iter #8    (V) | CCL: 0.000129077361296 | exact loss: 0.000129019619539 | change (V): 1.28396\n",
      "\tsubiter #3    | CCL: 0.000127546946277 | exact loss: 0.000127491436231 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000126076588317 | exact loss: 0.000126023149989 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000124661072523 | exact loss: 0.000124609565844 | change (U): 0.00000\n",
      "iter #8    (U) | CCL: 0.000124200876324 | exact loss: 0.000124149984620 | change (U): 0.00713\n",
      "iter #9    (V) | CCL: 0.000124178046406 | exact loss: 0.000124127859217 | change (V): 1.23344\n",
      "\tsubiter #3    | CCL: 0.000122805814392 | exact loss: 0.000122757375228 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000121485668265 | exact loss: 0.000121438857756 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000120212805162 | exact loss: 0.000120167519158 | change (U): 0.00000\n",
      "iter #9    (U) | CCL: 0.000119798560441 | exact loss: 0.000119753761074 | change (U): 0.00679\n",
      "iter #10   (V) | CCL: 0.000119777636717 | exact loss: 0.000119733443758 | change (V): 1.18772\n",
      "\tsubiter #3    | CCL: 0.000118540794626 | exact loss: 0.000118497986432 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000117349332647 | exact loss: 0.000117307819657 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000116198820374 | exact loss: 0.000116158524645 | change (U): 0.00000\n",
      "iter #10   (U) | CCL: 0.000115824019046 | exact loss: 0.000115784112925 | change (U): 0.00648\n",
      "iter #11   (V) | CCL: 0.000115804761323 | exact loss: 0.000115765380000 | change (V): 1.14589\n",
      "\tsubiter #3    | CCL: 0.000114684254792 | exact loss: 0.000114645983555 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000113603477749 | exact loss: 0.000113566248958 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000112558334782 | exact loss: 0.000112522089666 | change (U): 0.00000\n",
      "iter #11   (U) | CCL: 0.000112217531506 | exact loss: 0.000112181602082 | change (U): 0.00620\n",
      "iter #12   (V) | CCL: 0.000112199740631 | exact loss: 0.000112164268269 | change (V): 1.10733\n",
      "\tsubiter #3    | CCL: 0.000111179624578 | exact loss: 0.000111145052954 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000110194467375 | exact loss: 0.000110160745017 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000109240473144 | exact loss: 0.000109207555372 | change (U): 0.00000\n",
      "iter #12   (U) | CCL: 0.000108929106256 | exact loss: 0.000108896447382 | change (U): 0.00595\n",
      "iter #13   (V) | CCL: 0.000108912614065 | exact loss: 0.000108880356022 | change (V): 1.07160\n",
      "\tsubiter #3    | CCL: 0.000107979525443 | exact loss: 0.000107948007159 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000107077358844 | exact loss: 0.000107046540830 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000106202584838 | exact loss: 0.000106172432823 | change (U): 0.00000\n",
      "iter #13   (U) | CCL: 0.000105916826265 | exact loss: 0.000105886889099 | change (U): 0.00572\n",
      "iter #14   (V) | CCL: 0.000105901489053 | exact loss: 0.000105871905938 | change (V): 1.03837\n",
      "\tsubiter #3    | CCL: 0.000105044206861 | exact loss: 0.000105015238527 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000104214421714 | exact loss: 0.000104186037602 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000103408840290 | exact loss: 0.000103381013867 | change (U): 0.00000\n",
      "iter #14   (U) | CCL: 0.000103145470368 | exact loss: 0.000103117824291 | change (U): 0.00550\n",
      "iter #15   (V) | CCL: 0.000103131164380 | exact loss: 0.000103103833292 | change (V): 1.00737\n",
      "\tsubiter #3    | CCL: 0.000102340243715 | exact loss: 0.000102313429394 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000101573905303 | exact loss: 0.000101547583883 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000100829064594 | exact loss: 0.000100803215340 | change (U): 0.00000\n",
      "iter #15   (U) | CCL: 0.000100585368060 | exact loss: 0.000100559671844 | change (U): 0.00531\n",
      "iter #16   (V) | CCL: 0.000100571986186 | exact loss: 0.000100546572192 | change (V): 0.97840\n",
      "\tsubiter #3    | CCL: 0.000099839454736 | exact loss: 0.000099814479829 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000099129016317 | exact loss: 0.000099104461690 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000098437770904 | exact loss: 0.000098413620196 | change (U): 0.00000\n",
      "iter #16   (U) | CCL: 0.000098211450749 | exact loss: 0.000098187431239 | change (U): 0.00513\n",
      "iter #17   (V) | CCL: 0.000098198899970 | exact loss: 0.000098175135040 | change (V): 0.95127\n",
      "\tsubiter #3    | CCL: 0.000097518006894 | exact loss: 0.000097494618831 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000096857072886 | exact loss: 0.000096834046734 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000096213361204 | exact loss: 0.000096190683934 | change (U): 0.00000\n",
      "iter #17   (U) | CCL: 0.000096002467491 | exact loss: 0.000095979903765 | change (U): 0.00496\n",
      "iter #18   (V) | CCL: 0.000095990666817 | exact loss: 0.000095968334214 | change (V): 0.92581\n",
      "\tsubiter #3    | CCL: 0.000095355675355 | exact loss: 0.000095333669251 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000094738805899 | exact loss: 0.000094717114292 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000094137466586 | exact loss: 0.000094116079008 | change (U): 0.00000\n",
      "iter #18   (U) | CCL: 0.000093940337718 | exact loss: 0.000093919049267 | change (U): 0.00481\n",
      "iter #19   (V) | CCL: 0.000093929216484 | exact loss: 0.000093908139122 | change (V): 0.90188\n",
      "\tsubiter #3    | CCL: 0.000093335232897 | exact loss: 0.000093314440832 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000092757782761 | exact loss: 0.000092737266281 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000092194403280 | exact loss: 0.000092174153901 | change (U): 0.00000\n",
      "iter #19   (U) | CCL: 0.000092009617604 | exact loss: 0.000091989455458 | change (U): 0.00466\n",
      "iter #20   (V) | CCL: 0.000091999114032 | exact loss: 0.000091979145753 | change (V): 0.87935\n",
      "\tsubiter #3    | CCL: 0.000091441946596 | exact loss: 0.000091422229567 | change (U): 0.00000\n",
      "\tsubiter #6    | CCL: 0.000090899932453 | exact loss: 0.000090880458751 | change (U): 0.00000\n",
      "\tsubiter #9    | CCL: 0.000090370724376 | exact loss: 0.000090351487070 | change (U): 0.00000\n",
      "iter #20   (U) | CCL: 0.000090197060294 | exact loss: 0.000090177900312 | change (U): 0.00453\n"
     ]
    }
   ],
   "source": [
    "ranks=[20,40]\n",
    "# ranks=7\n",
    "# nL = []\n",
    "ccL = []\n",
    "# nU_q = []\n",
    "# nV_q = []\n",
    "\n",
    "ccU_q = []\n",
    "ccV_q = []\n",
    "for k=ranks\n",
    "    println(\"computing rank $(k) approximation\")\n",
    "    # Uₖ, Vₖ, Ξ_q, U₀, V₀ = curvature_corrected_sNMF_precomp(M, q, data, log_q_data, k; \n",
    "    #     max_iter = CC_iter, debug_freq = debug_int, init_type=\"kmeans\",\n",
    "    #     ENMF_const = offset, \n",
    "    #     max_U_iter=U_iters, U_debug=U_debug_int);\n",
    "    Uₖ, Vₖ, Ξ_q, U₀, V₀ = curvature_corrected_sNMF_precomp(M, q, data, log_q_data, k; \n",
    "        max_iter = CC_iter, debug_freq = debug_int, init_type=\"kmeans\",\n",
    "        ENMF_const = offset, \n",
    "        max_U_iter=U_iters, U_debug=U_debug_int);\n",
    "    # push!(nU_q, U₀)\n",
    "    # push!(nV_q, V₀)\n",
    "    # Ξ_naive_coords = U₀ * V₀\n",
    "    # Ξ_naive = get_vector.(Ref(M), Ref(q), [Ξ_naive_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    push!(ccU_q,Uₖ)\n",
    "    push!(ccV_q,Vₖ)\n",
    "    # loss_naive = exact_loss(M, q, data, Ξ_naive);\n",
    "    loss_cc = exact_loss(M, q, data, Ξ_q);\n",
    "    # push!(nL, loss_naive)\n",
    "    push!(ccL, loss_cc)\n",
    "    # println(\"computing rank $(k) approximation (U first)\")\n",
    "    # Uₖ, Vₖ, Ξ_q, U₀, V₀ = curvature_corrected_sNMF(M, q, data, k; ENMF_const = offset, ENMF_iter = E_iter, max_iter = CC_iter, debug_freq = debug_int, init_type=\"kmeans\", first_factor=\"U\");\n",
    "    # push!(ccU_q_uf,Uₖ)\n",
    "    # push!(ccV_q_uf,Vₖ)\n",
    "    # loss_cc = exact_loss(M, q, data, Ξ_q);\n",
    "    # push!(ccL_uf, loss_cc)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "save(\"IIT_power_voxels_2040.jld\",\"ccV_q\",ccV_q,\"ccU_q\",ccU_q,\"ccL\",ccL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ccU_q_proj = []\n",
    "for k=ranks\n",
    "    push!(ccU_q_proj, get_corrected_factors(M, q, ccU_q_vf[k-9], ccV_q_vf[k-9]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_diffs = []\n",
    "for k=ranks\n",
    "    push!(U_diffs, norm(ccU_q_proj[k-9] - ccU_q_vf[k-9]))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum(U_diffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks,[nL, ccL_vf],label=[\"exact loss (naive approx)\" \"exact loss (CC)\"],xaxis=\"approximation rank\",yaxis=\"exact loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks, ccL_vf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_V = ccV_q[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(this_V)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_TM = get_vector.(Ref(M), Ref(q), [this_V[l,:] for l=1:10], Ref(DefaultOrthonormalBasis()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(V_TM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V_TM[1][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_U = ccU_q[1];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_max = maximum(this_U; dims=1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "U_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_name = \"IIT_power\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k=ranks\n",
    "    ccU = ccU_q[k-9]\n",
    "    ccV = ccV_q[k-9]\n",
    "\n",
    "    ccV_TM = get_vector.(Ref(M), Ref(q), [ccV[l,:] for l=1:k], Ref(DefaultOrthonormalBasis()))\n",
    "    ccU_max = maximum(ccU; dims=1)\n",
    "    overall_factor_list_cc = exp.(Ref(M), Ref(q), [ccU_max[i] * ccV_TM[i] for i=1:k]) \n",
    "    # factors\n",
    "    \n",
    "    for j=1:k\n",
    "        # factor_naive = factor_list_naive[j];\n",
    "        # # factor_2D_naive = reshape(factor_naive, (10, 10)); # only for patches\n",
    "        # factor_2D_naive = reshape(factor_naive, (48, 48)); # for full data\n",
    "        # fig_filename_naive = @sprintf(\"%s/k%d/factor%d_naive.asy\", folder_name, k, j);\n",
    "        # asymptote_export_SPD(fig_filename_naive, data=factor_2D_naive, scale_axes=(2,2,2)); \n",
    "        # render_asymptote(fig_filename_naive)\n",
    "        factor_cc_unscaled = overall_factor_list_cc[j];\n",
    "        # factor_cc = overall_factor_list_cc[j];\n",
    "        \n",
    "        eigmaxes = opnorm.(factor_cc_unscaled, 2);\n",
    "        if maximum(eigmaxes) < 1\n",
    "            factor_cc = factor_cc_unscaled / maximum(eigmaxes);\n",
    "        else\n",
    "            factor_cc = factor_cc_unscaled\n",
    "        end\n",
    "        factor_2D_cc = reshape(factor_cc, (10, 10));\n",
    "        fig_filename_cc = @sprintf(\"%s/k%d/cc_factor%d.asy\", folder_name, k, j);\n",
    "        asymptote_export_SPD(fig_filename_cc, data=factor_2D_cc, scale_axes=(2,2,2)); \n",
    "        render_asymptote(fig_filename_cc)     \n",
    "        \n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ni_atlas = niread(\"../../../data/IIT_WM_atlas.nii.gz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(ni_atlas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is from z = 56, but let's try with a different slice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_atlas = ni_atlas[41:140,61:160,56,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(sub_atlas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_desikan_prob = niread(\"../../../data/IIT_GM_Desikan_prob.nii.gz\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "size(GM_desikan_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GM_desikan_prob = GM_desikan_prob[41:140,61:160,56,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(sub_GM_desikan_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_desikan_mask = niread(\"../../../data/IIT_GM_Desikan_mask.nii\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(GM_desikan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_GM_desikan_mask = GM_desikan_mask[41:140,61:160,56];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(sub_GM_desikan_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_mask = reshape(sub_GM_desikan_mask,(10000,));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_GM_probs = reshape(sub_GM_desikan_prob,(10000,84));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(vec_GM_probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GM_probs_masked = vec_GM_probs[vec_mask .> 0,:];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(GM_probs_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = vec(predata[41:140,61:160,56]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_V = ccV_q_vf[10];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_test_data = log.(Ref(M), Ref(q), test_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_V_TM = get_vector.(Ref(M), Ref(q), [this_V[l,:] for l=1:10], Ref(DefaultOrthonormalBasis()));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dists = [norm.(Ref(log_test_data[i]).-this_V_TM) for i=1:n];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(all_dists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris = []\n",
    "vms_0p1 = []\n",
    "vms_0p01 = []\n",
    "vms_0p5 = []\n",
    "vms_0p1_cc = []\n",
    "vms_0p01_cc = []\n",
    "vms_0p5_cc = []\n",
    "ris_cc = []\n",
    "vms_cc = []\n",
    "vec_mask = reshape(sub_GM_desikan_mask,(10000,));\n",
    "vec_GM_probs = reshape(sub_GM_desikan_prob,(10000,84));\n",
    "GM_probs_masked = vec_GM_probs[vec_mask .> 0,:];\n",
    "atlas_assign = mapslices(argmax, GM_probs_masked, dims=2)[:];\n",
    "# log_test_data = log.(Ref(M), Ref(q), test_data[vec_mask .> 0]);\n",
    "# n_test = size(log_test_data)[1];\n",
    "for r=ranks\n",
    "    # ccV = ccV_q_vf[r-9]\n",
    "    # ccV_TM = get_vector.(Ref(M), Ref(q), [ccV[l,:] for l=1:r], Ref(DefaultOrthonormalBasis()));\n",
    "    # nV = nV_q[r-9]\n",
    "    # nV_TM = get_vector.(Ref(M), Ref(q), [nV[l,:] for l = 1:r], Ref(DefaultOrthonormalBasis()));\n",
    "    # rep_data = repeat(log_test_data,outer=(1,r));\n",
    "    this_U = nU_q[r-9]\n",
    "    this_U_masked = this_U[vec_mask .> 0,:];\n",
    "    n_assign = mapslices(argmax, this_U_masked, dims=2)[:];\n",
    "    # cc_assign=argmin.([[curvature_corrected_loss_fromlog(M, q, [log_test_data[i]], [ccV_TM[j]]) for j=1:r] for i=1:n_test]);\n",
    "    # n_assign=argmin.([[curvature_corrected_loss_fromlog(M, q, [log_test_data[i]], [nV_TM[j]]) for j=1:r] for i=1:n_test]);\n",
    "    \n",
    "    # cc_assign = mapslices(argmin, norm.(rep_data.-ccV_TM');dims=2)[vec_mask .> 0];\n",
    "    # n_assign = mapslices(argmin, norm.(rep_data.-nV_TM');dims=2)[vec_mask .> 0];\n",
    "    \n",
    "    # ri = get_rand_idx(get_label_mat(GM_probs_masked),get_label_mat(this_U_masked));\n",
    "    # vm_0p5 = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked, dims=2);β=0.5)\n",
    "    # vm_0p1 = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked, dims=2);β=0.1)\n",
    "    # vm_0p01 = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked, dims=2);β=0.01)\n",
    "\n",
    "    ri = randindex(atlas_assign, n_assign)\n",
    "    vm_0p5 = vmeasure(atlas_assign, n_assign;β=0.5)\n",
    "    vm_0p1 = vmeasure(atlas_assign, n_assign;β=0.1)\n",
    "    vm_0p01 = vmeasure(atlas_assign, n_assign;β=0.01)\n",
    "    push!(ris, ri)\n",
    "    push!(vms_0p1, vm_0p1)\n",
    "    push!(vms_0p01, vm_0p01)\n",
    "    push!(vms_0p5, vm_0p5)\n",
    "    this_U_cc = ccU_q_vf[r-9]\n",
    "    this_U_masked_cc = this_U_cc[vec_mask .> 0,:];\n",
    "    cc_assign = mapslices(argmax, this_U_masked_cc, dims=2)[:];\n",
    "    # ri_cc = get_rand_idx(get_label_mat(GM_probs_masked),get_label_mat(this_U_masked_cc));\n",
    "    # vm_cc = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked_cc, dims=2);β=0.5)\n",
    "    # vm_0p5 = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked_cc, dims=2);β=0.5)\n",
    "    # vm_0p1 = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked_cc, dims=2);β=0.1)\n",
    "    # vm_0p01 = vmeasure(mapslices(argmax, GM_probs_masked, dims=2), mapslices(argmax, this_U_masked_cc, dims=2);β=0.01)\n",
    "    ri_cc = randindex(atlas_assign, cc_assign)\n",
    "    vm_0p5 = vmeasure(atlas_assign, cc_assign;β=0.5)\n",
    "    vm_0p1 = vmeasure(atlas_assign, cc_assign;β=0.1)\n",
    "    vm_0p01 = vmeasure(atlas_assign, cc_assign;β=0.01)\n",
    "\n",
    "    push!(ris_cc, ri_cc)\n",
    "    # push!(vms_cc, vm_cc)\n",
    "    push!(vms_0p1_cc, vm_0p1)\n",
    "    push!(vms_0p01_cc, vm_0p01)\n",
    "    push!(vms_0p5_cc, vm_0p5)\n",
    "    @printf(\"rank %i done\\n\", r)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "typeof(atlas_assign[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ris = reduce(hcat, ris);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(test_ris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ris[1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks,[[ris[i-9][2] for i=ranks] [ris_cc[i-9][2] for i=ranks]],label=[\"ri\" \"ri cc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks,[vms_0p5,vms_0p1,vms_0p01],label=[\"vms 0p5\" \"vms 0p1\" \"vms 0p01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks,[vms_0p5_cc,vms_0p1_cc,vms_0p01_cc],label=[\"vms 0p5\" \"vms 0p1\" \"vms 0p01\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,1],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,1],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,2],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,2],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,3],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,3],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,4],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,4],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,5],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,5],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,6],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,6],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(nU_q[1][:,7],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(reshape(ccU_q_vf[1][:,7],(100,100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k=ranks\n",
    "    ccU = ccU_q[k-1]\n",
    "    ccV = ccV_q[k-1]\n",
    "    ccU_proj = ccU_q_proj[k-1]\n",
    "    nU = nU_q[k-1]\n",
    "    nV = nV_q[k-1]\n",
    "    Ξ_naive_coords = nU * nV\n",
    "    Ξ_cc_coords = ccU * ccV\n",
    "    Ξ_cc_proj_coords = ccU_proj * ccV\n",
    "    Ξ_naive = get_vector.(Ref(M), Ref(q), [Ξ_naive_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    Ξ_cc = get_vector.(Ref(M), Ref(q), [Ξ_cc_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    Ξ_cc_proj = get_vector.(Ref(M), Ref(q), [Ξ_cc_proj_coords[l,:] for l=1:n[1]], Ref(DefaultOrthonormalBasis()))\n",
    "    nV_TM = get_vector.(Ref(M), Ref(q), [nV[l,:] for l=1:k], Ref(DefaultOrthonormalBasis()))\n",
    "    ccV_TM = get_vector.(Ref(M), Ref(q), [ccV[l,:] for l=1:k], Ref(DefaultOrthonormalBasis()))\n",
    "    nU_max = maximum(nU; dims=1)\n",
    "    ccU_max = maximum(ccU; dims=1)\n",
    "    ccU_proj_max = maximum(ccU_proj; dims=1)\n",
    "    overall_factor_list_naive = exp.(Ref(M), Ref(q), [nU_max[i] * nV_TM[i] for i=1:k])\n",
    "    overall_factor_list_cc = exp.(Ref(M), Ref(q), [ccU_max[i] * ccV_TM[i] for i=1:k])\n",
    "    overall_factor_list_cc_proj = exp.(Ref(M), Ref(q), [ccU_proj_max[i] * ccV_TM[i] for i=1:k])\n",
    "    fig_filename_naive = @sprintf(\"%s/k%d/overall_factors_naive.asy\", folder_name, k)\n",
    "    fig_filename_cc = @sprintf(\"%s/k%d/overall_factors_cc.asy\", folder_name, k)\n",
    "    fig_filename_cc_proj = @sprintf(\"%s/k%d/overall_factors_cc_proj.asy\", folder_name, k)\n",
    "    # asymptote_export_SPD(fig_filename_naive, data=overall_factor_list_naive, scale_axes=(2, 2, 2));\n",
    "    asymptote_export_SPD(fig_filename_naive, data=overall_factor_list_naive, scale_axes=(axes_scale_n, axes_scale_n, axes_scale_n));\n",
    "    render_asymptote(fig_filename_naive)\n",
    "    # asymptote_export_SPD(fig_filename_cc, data=overall_factor_list_cc, scale_axes=(2, 2, 2)); \n",
    "    asymptote_export_SPD(fig_filename_cc, data=overall_factor_list_cc, scale_axes=(axes_scale, axes_scale, axes_scale)); \n",
    "    render_asymptote(fig_filename_cc)\n",
    "    \n",
    "    asymptote_export_SPD(fig_filename_cc_proj, data=overall_factor_list_cc_proj, scale_axes=(axes_scale, axes_scale, axes_scale)); \n",
    "    render_asymptote(fig_filename_cc_proj)\n",
    "    \n",
    "    # reconstructions\n",
    "    reconst_1D_naive = exp.(Ref(M), Ref(q), Ξ_naive);\n",
    "    reconst_1D_cc = exp.(Ref(M), Ref(q), Ξ_cc);\n",
    "    reconst_1D_cc_proj = exp.(Ref(M), Ref(q), Ξ_cc_proj);\n",
    "    # factor_M = exp.(Ref(M), Ref(q), get_vector.(Ref(M), Ref(q), [this_U[i,1] * transpose(this_V)[1,:] for i=1:n], Ref(DefaultOrthonormalBasis())));\n",
    "    # reconst_2D_naive = reshape(reconst_1D_naive, (10, 10));\n",
    "    reconst_2D_naive = reshape(reconst_1D_naive, (48, 48));\n",
    "    # reconst_2D_cc = reshape(reconst_1D_cc, (10, 10));\n",
    "    reconst_2D_cc = reshape(reconst_1D_cc, (48, 48));\n",
    "    reconst_2D_cc_proj = reshape(reconst_1D_cc_proj, (48, 48));\n",
    "    fig_filename_naive = @sprintf(\"%s/k%d/reconst_naive.asy\", folder_name, k)\n",
    "    fig_filename_cc = @sprintf(\"%s/k%d/reconst_cc.asy\", folder_name, k)\n",
    "    fig_filename_cc_proj = @sprintf(\"%s/k%d/reconst_cc_proj.asy\", folder_name, k)\n",
    "    asymptote_export_SPD(fig_filename_naive, data=reconst_2D_naive, scale_axes=(2, 2, 2)); \n",
    "    render_asymptote(fig_filename_naive)\n",
    "    asymptote_export_SPD(fig_filename_cc, data=reconst_2D_cc, scale_axes=(2, 2, 2)); \n",
    "    render_asymptote(fig_filename_cc)\n",
    "    asymptote_export_SPD(fig_filename_cc_proj, data=reconst_2D_cc_proj, scale_axes=(2, 2, 2)); \n",
    "    render_asymptote(fig_filename_cc_proj)\n",
    "    \n",
    "    # factors\n",
    "    factor_list_naive = [exp.(Ref(M), Ref(q), [nU[i,j] * nV_TM[j] for i=1:n[1]]) for j=1:k];\n",
    "    factor_list_cc = [exp.(Ref(M), Ref(q), [ccU[i,j] * ccV_TM[j] for i=1:n[1]]) for j=1:k];\n",
    "    factor_list_cc_proj = [exp.(Ref(M), Ref(q), [ccU_proj[i,j] * ccV_TM[j] for i=1:n[1]]) for j=1:k];\n",
    "    \n",
    "    for j=1:k\n",
    "        # factor_naive = factor_list_naive[j];\n",
    "        # # factor_2D_naive = reshape(factor_naive, (10, 10)); # only for patches\n",
    "        # factor_2D_naive = reshape(factor_naive, (48, 48)); # for full data\n",
    "        # fig_filename_naive = @sprintf(\"%s/k%d/factor%d_naive.asy\", folder_name, k, j);\n",
    "        # asymptote_export_SPD(fig_filename_naive, data=factor_2D_naive, scale_axes=(2,2,2)); \n",
    "        # render_asymptote(fig_filename_naive)\n",
    "        factor_cc_unscaled = factor_list_cc[j];\n",
    "        eigmaxes = opnorm.(factor_cc_unscaled, 2);\n",
    "        if maximum(eigmaxes) < 1\n",
    "            factor_cc = factor_cc_unscaled / maximum(eigmaxes);\n",
    "        else\n",
    "            factor_cc = factor_cc_unscaled\n",
    "        end\n",
    "        # factor_2D_cc = reshape(factor_cc, (10, 10));\n",
    "        factor_2D_cc = reshape(factor_cc, (48, 48));\n",
    "        fig_filename_cc = @sprintf(\"%s/k%d/cc_factor%d.asy\", folder_name, k, j);\n",
    "        asymptote_export_SPD(fig_filename_cc, data=factor_2D_cc, scale_axes=(2,2,2)); \n",
    "        render_asymptote(fig_filename_cc)\n",
    "        \n",
    "        factor_cc_proj_unscaled = factor_list_cc_proj[j];\n",
    "        eigmaxes = opnorm.(factor_cc_proj_unscaled, 2);\n",
    "        if maximum(eigmaxes) < 1\n",
    "            factor_cc_proj = factor_cc_proj_unscaled / maximum(eigmaxes);\n",
    "        else\n",
    "            factor_cc_proj = factor_cc_proj_unscaled\n",
    "        end\n",
    "        # factor_2D_cc = reshape(factor_cc, (10, 10));\n",
    "        factor_2D_cc_proj = reshape(factor_cc_proj, (48, 48));\n",
    "        fig_filename_cc_proj = @sprintf(\"%s/k%d/cc_proj_factor%d.asy\", folder_name, k, j);\n",
    "        asymptote_export_SPD(fig_filename_cc_proj, data=factor_2D_cc_proj, scale_axes=(2,2,2)); \n",
    "        render_asymptote(fig_filename_cc_proj)       \n",
    "        \n",
    "    end\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IIT Atlas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"IIT/true.asy\"\n",
    "# # asymptote_export_SPD(filename, data = reshape(data, (10, 10)), scale_axes=(2, 2, 2));\n",
    "# asymptote_export_SPD(filename, data = predata2[67:116,85:134,100], scale_axes=(2, 2, 2));\n",
    "\n",
    "# render_asymptote(filename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = Matrix(I, 3, 3) .* 1e-5\n",
    "# q = Matrix(I, 3, 3) .* 1e-4\n",
    "log_q_data = log.(Ref(M), Ref(q), data2);  # ∈ T_q P(3)^n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the idea is that the coordinates should all be in the same..... higher-dimensional quadrant? Or do we check the inner products directly? Or is this equivalent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_coords_mat = reduce(hcat, get_coordinates.(Ref(M), Ref(q), log_q_data, Ref(DefaultOrthonormalBasis())));\n",
    "inner_pdts = data_coords_mat' * data_coords_mat;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(log_q_data)[1]^2 - count(inner_pdts .>= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vms_cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks,ris_cc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(ranks,[vms_0p01,vms_0p1,vms_0p5],label=[\"beta = 0.01\" \"beta = 0.1\" \"beta = 0.5\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_total_mat = reduce(hcat, f1_total);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size(f1_total_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(f1_total_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_f1(get_label_mat(GM_probs_masked),get_label_mat(this_U_masked);avg_type=\"equal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(get_used_labels(get_label_mat(GM_probs_masked)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap(get_used_labels(get_label_mat(this_U_masked)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figuring out random Julia stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=10;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time curvature_corrected_sNMF_precomp(M, q, data, log_q_data, k; \n",
    "        max_iter = CC_iter, debug_freq = debug_int, init_type=\"kmeans\",\n",
    "        ENMF_const = offset, \n",
    "        max_U_iter=U_iters, U_debug=U_debug_int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@time curvature_corrected_sNMF_precomp(M, q, data, log_q_data, k; \n",
    "        max_iter = CC_iter, debug_freq = debug_int, init_type=\"kmeans\",\n",
    "        ENMF_const = offset, \n",
    "        max_U_iter=U_iters, U_debug=U_debug_int);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.5",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
