{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-rank approximation on $\\mathcal{P}(d)$ - the space of $d$-dimensional SPD matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to get some intuition in different approaches for computing low-rank approximations for manifold-valued signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Manifolds\n",
    "using Manopt\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PowerManifold(SymmetricPositiveDefinite(3), NestedPowerRepresentation(), 100)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# initialize SPD power manifold P(d)^d1\n",
    "dd = 3  # size of the SPD matrices, i.e., ∈ R^d×d\n",
    "M_base = SymmetricPositiveDefinite(dd)\n",
    "d = manifold_dimension(M_base)\n",
    "d1 = 100  # size of the signal\n",
    "M = PowerManifold(M_base, NestedPowerRepresentation(), d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0 0.0 0.0; 0.0 0.0 0.0; 0.0 0.0 0.0]\n"
     ]
    }
   ],
   "source": [
    "e = 1. * Matrix(I, dd, dd)\n",
    "# compute basis on M_base\n",
    "Θ = get_basis(M_base, e, DefaultOrthonormalBasis())\n",
    "#  construct data\n",
    "Q = fill(e, d1)\n",
    "# draw random tvectors \n",
    "τ = 2.  # variance\n",
    "σ = .05  # variance\n",
    "# Xₑⁱ = zeros(d)\n",
    "# Xₑⁱ[1] = 1.\n",
    "# Xₑ = get_vector(M_base, e, Xₑⁱ, Θ)\n",
    "Xₑ = Θ.data[1]\n",
    "\n",
    "Random.seed!(31)\n",
    "predata = [exp(M_base, e, sqrt(τ) * randn(1)[1] * Xₑ) for i in 1:d1]\n",
    "\n",
    "data = [exp(M_base, predata[i], random_tangent(M_base, predata[i], Val(:Gaussian), σ)) for i in 1:d1] # ∈ P(3)^d1\n",
    "log_Q_data = log(M, Q, data)  # ∈ T_e P(3)^d1\n",
    "println(Xₑ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to investigate how reliable both ranks are, i.e., we don't want that something looks low-rank, but in reality is higher rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       "   0.20030061285052259\n",
       "   0.23473294140142664\n",
       "   0.31265402158642613\n",
       "   0.3306014192967376\n",
       "   0.3946823528716723\n",
       " 480.59320854019387"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute SVD\n",
    "# compute Gramm Matrix\n",
    "Gramm_Q = [inner(M_base, e, log_Q_data[k], log_Q_data[l]) for k=1:d1, l=1:d1]\n",
    "# compute Σ and V\n",
    "(sqSigma, V) = eigen(Symmetric(Gramm_Q), d1-min(d1-1,d-1):d1)\n",
    "# compute U\n",
    "U = [1/sqrt(sqSigma[i]) * sum([V[k,i] * log_Q_data[k] for k in 1:d1]) for i in 1:d]\n",
    "\n",
    "sqSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3×3 Matrix{Float64}:\n",
       " -0.999971    0.00196278  0.00126507\n",
       "  0.00196278  0.00624225  0.00162757\n",
       "  0.00126507  0.00162757  0.00169994"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "U[end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "β (generic function with 1 method)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "function β(κ)\n",
    "    (κ < 0) && return sinh(sqrt(-κ)) / ( sqrt((-κ)))\n",
    "    (κ > 0) && return sin(sqrt(κ)) / (sqrt(κ))\n",
    "    return 1.0 # cuvature zero.\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6×6 Matrix{Float64}:\n",
       "  1.04169       4.7573       1.15559    -0.0390015   -0.0135617   -0.00268737\n",
       "  4.7573      583.679        8.40348    -4.73989     -0.899143    -0.0174109\n",
       "  1.15559       8.40348    527.562      -0.0683755   -3.04085     -1.08721\n",
       " -0.0390015    -4.73989     -0.0683755   1.03909      0.00735125  -9.16997e-5\n",
       " -0.0135617    -0.899143    -3.04085     0.00735125   1.01955      0.00621049\n",
       " -0.00268737   -0.0174109   -1.08721    -9.16997e-5   0.00621049   1.00278"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# we want to compute the metric tensor entries in default ONB at e and then compute g_ij so that we don't have to reevaluate this all the time\n",
    "gᵢⱼ = zeros(d,d)\n",
    "for k=1:d1\n",
    "    Ξₖ = get_basis(M_base, e, DiagonalizingOrthonormalBasis(log_Q_data[k]))\n",
    "    κₖ = Ξₖ.data.eigenvalues\n",
    "    βₖ = [β(κₖ[l]) for l in 1:d]\n",
    "    gᵢⱼ += 1/d1 * [sum([βₖ[l]^2 * inner(M_base, e, Θ.data[i], Ξₖ.data.vectors[l]) * inner(M_base, e, Θ.data[j], Ξₖ.data.vectors[l]) for l=1:d]) for i=1:d, j=1:d]\n",
    "end\n",
    "gᵢⱼ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6-element Vector{Float64}:\n",
       "   0.21302896045266548\n",
       "   0.2671352985274962\n",
       "   0.3244334499955881\n",
       " 165.4392037998312\n",
       " 188.58425319157402\n",
       " 493.9524469033112"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# compute SVD\n",
    "# compute rescaled Gramm Matrix\n",
    "reweighted_Gramm_Q = [sum([gᵢⱼ[i,j] * get_coordinates(M_base, e, log_Q_data[k], Θ)[i] * get_coordinates(M_base, e, log_Q_data[l], Θ)[j] for i=1:d, j=1:d]) for k=1:d1, l=1:d1]\n",
    "# compute Σ and V\n",
    "(reweighted_sqSigma, reweighted_V) = eigen(Symmetric(reweighted_Gramm_Q ), d1-min(d1-1,d-1):d1)\n",
    "# compute U\n",
    "reweighted_U = [1/sqrt(reweighted_sqSigma[i]) * sum([reweighted_V[k,i] * log_Q_data[k] for k in 1:d1]) for i in 1:d]\n",
    "\n",
    "reweighted_sqSigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_distance = distance(M, data, Q)\n",
    "tangent_distances_r = zeros(d)\n",
    "distances_r = zeros(d)\n",
    "reweighted_tangent_distances_r = zeros(d)\n",
    "reweighted_distances_r = zeros(d)\n",
    "\n",
    "for rank in 1:d\n",
    "    log_Q_data_r = [sum([U[i] * sqrt(sqSigma[i]) * V[k,i] for i in d-rank+1:d]) for k in 1:d1]\n",
    "    reweighted_log_Q_data_r = [sum([reweighted_U[i] * sqrt(reweighted_sqSigma[i]) * reweighted_V[k,i] for i in d-rank+1:d]) for k in 1:d1]\n",
    "    # expoentiate back\n",
    "    data_r = exp(M, Q, log_Q_data_r)\n",
    "    reweighted_data_r = exp(M, Q, reweighted_log_Q_data_r)\n",
    "\n",
    "\n",
    "    # compute tangent space error\n",
    "    tangent_distances_r[rank] = norm(M, Q,  log_Q_data - log_Q_data_r)\n",
    "    reweighted_tangent_distances_r[rank] = norm(M,Q,  log_Q_data - reweighted_log_Q_data_r )\n",
    "\n",
    "\n",
    "    # compute manifold error\n",
    "    distances_r[rank] = distance(M, data, data_r)\n",
    "    reweighted_distances_r[rank] = distance(M, data, reweighted_data_r)\n",
    "end\n",
    "# TODO plot distances for every rank 1:6\n",
    "# It seems to pick the correct vectors, but the singular values do not yet reflect that well how low the rank actually is...\n",
    "# -> we can reweight the U's and the sigmas by normalizing them wrt old metric\n",
    "# the SPD manifold always has a couple of directions with negative curvature, check whether these are the same as the obtained directions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/wdiepeveen/Documents/PhD/Projects/8 - Manifold-valued tensor decomposition/src/manifold-valued-tensors/P3_example1.png\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot(1:d, [ref_distance * ones(d), distances_r, reweighted_distances_r], label = [\"reference\" \"standard inner product\" \"reweighted inner product\"])\n",
    "savefig(\"P3_example1.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
