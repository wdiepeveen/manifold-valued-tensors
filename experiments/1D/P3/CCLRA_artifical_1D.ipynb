{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Low-rank approximation on $\\mathcal{P}(d)$ - the space of $d$-dimensional SPD matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we want to get some intuition in different approaches for computing low-rank approximations for manifold-valued signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Manifolds\n",
    "using Manopt\n",
    "using LinearAlgebra\n",
    "using Random\n",
    "using Plots\n",
    "using LaTeXStrings\n",
    "using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "exact_loss (generic function with 2 methods)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "include(\"../../../src/decompositions/signals/naive_low_rank_approximation.jl\")\n",
    "include(\"../../../src/decompositions/signals/curvature_corrected_low_rank_approximation.jl\")\n",
    "include(\"../../../src/decompositions/signals/exact_low_rank_approximation.jl\")\n",
    "\n",
    "include(\"../../../src/functions/loss_functions/curvature_corrected_loss.jl\")\n",
    "include(\"../../../src/functions/loss_functions/exact_loss.jl\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data and construct manifold ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "M = SymmetricPositiveDefinite(3)\n",
    "d = manifold_dimension(M)\n",
    "n = 100  # 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0 0.0 0.0; 0.0 1.0 0.0; 0.0 0.0 0.0]"
     ]
    }
   ],
   "source": [
    "e = 1. * Matrix(I, 3, 3)\n",
    "# compute basis\n",
    "Θ = get_basis(M, e, DefaultOrthonormalBasis())\n",
    "#  construct data\n",
    "τ = 2.  # variance\n",
    "σ = .05  # variance\n",
    "Xₑ = Θ.data[4]\n",
    "print(Xₑ)\n",
    "\n",
    "Random.seed!(31)\n",
    "predata = [exp(M, e, sqrt(τ) * randn(1)[1] * Xₑ) for i in 1:n]\n",
    "\n",
    "data = [exp(M, predata[i], random_tangent(M, predata[i], Val(:Gaussian), σ)) for i in 1:n]; # ∈ P(3)^n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export slice image\n",
    "num_export = 10\n",
    "asymptote_export_SPD(\"results/artificial1D_orig.asy\", data=data[1:min(num_export,n)], scale_axes=(2,2,2)); "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct low rank approximation ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "q = mean(M, data)\n",
    "log_q_data = log.(Ref(M), Ref(q), data);  # ∈ T_q P(3)^n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(([[0.1751310774738713 -0.28822025707989934 0.14867957458385664; -0.2882202570798994 5.482417921008724e-5 0.2666920711573869; 0.14867957458385667 0.2666920711573869 0.15375617247976367], [0.13286097697732582 0.0978199956337 0.03391718753611986; 0.09781999563370003 -22.69196950255126 0.07846149333333327; 0.03391718753611986 0.07846149333333327 0.03496085952503056]], [0.04141185945717856 0.043589454988513694; -0.062377171919476435 0.06746220792835492; … ; 0.08428851980435229 -0.04426547676489212; 0.09977091731476738 0.09542655939149962]), [0.05179777061223446, 0.015948606491658798, 0.05660493646913368, 0.009919243079205645, 0.05294981080865168, 0.01597051307193173, 0.05776102150791481, 0.0090382802715633, 0.051570914309466524, 0.018407499028757636])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (eRr_q, eUr), costs = exact_low_rank_approximation(M, q, data, 2; stepsize=1/10000, max_iter=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10-element Vector{Float64}:\n",
       " 0.05179777061223446\n",
       " 0.015948606491658798\n",
       " 0.05660493646913368\n",
       " 0.009919243079205645\n",
       " 0.05294981080865168\n",
       " 0.01597051307193173\n",
       " 0.05776102150791481\n",
       " 0.0090382802715633\n",
       " 0.051570914309466524\n",
       " 0.018407499028757636"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#1 | computing naive low-rank approximation\n",
      "#1 | computing curvature corrected low-rank approximation\n",
      "#1 | computing exact low-rank approximation\n",
      "#2 | computing naive low-rank approximation\n",
      "#2 | computing curvature corrected low-rank approximation\n",
      "#2 | computing exact low-rank approximation\n",
      "#3 | computing naive low-rank approximation\n",
      "#3 | computing curvature corrected low-rank approximation\n",
      "#3 | computing exact low-rank approximation\n",
      "#4 | computing naive low-rank approximation\n",
      "#4 | computing curvature corrected low-rank approximation\n",
      "#4 | computing exact low-rank approximation\n",
      "#5 | computing naive low-rank approximation\n",
      "#5 | computing curvature corrected low-rank approximation\n",
      "#5 | computing exact low-rank approximation\n",
      "#6 | computing naive low-rank approximation\n",
      "#6 | computing curvature corrected low-rank approximation\n",
      "#6 | computing exact low-rank approximation\n"
     ]
    }
   ],
   "source": [
    "max_iter = 50\n",
    "\n",
    "nR_q = []\n",
    "nU = []\n",
    "ccR_q = []\n",
    "ccU = []\n",
    "eR_q = []\n",
    "eU = []\n",
    "eCosts = []\n",
    "for i in 1:d  \n",
    "    println(\"#$(i) | computing naive low-rank approximation\")\n",
    "    nRr_q, nUr = naive_low_rank_approximation(M, q, data, i)\n",
    "    push!(nR_q, nRr_q)\n",
    "    push!(nU, nUr)\n",
    "    println(\"#$(i) | computing curvature corrected low-rank approximation\")\n",
    "    ccRr_q, ccUr = curvature_corrected_low_rank_approximation(M, q, data, i); \n",
    "    push!(ccR_q, ccRr_q)\n",
    "    push!(ccU, ccUr)\n",
    "    println(\"#$(i) | computing exact low-rank approximation\")\n",
    "    (eRr_q, eUr), eCostsr = exact_low_rank_approximation(M, q, data, i; stepsize=1/100000, max_iter=max_iter); \n",
    "    push!(eR_q, eRr_q)\n",
    "    push!(eU, eUr)\n",
    "    push!(eCosts, eCostsr)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_distance = sum(distance.(Ref(M), Ref(q), data).^2)\n",
    "\n",
    "naive_tangent_distances_r = zeros(d)\n",
    "predicted_naive_distances_r= zeros(d)\n",
    "true_naive_distances_r= zeros(d)\n",
    "\n",
    "curvature_corrected_tangent_distances_r = zeros(d)\n",
    "predicted_curvature_corrected_distances_r = zeros(d)\n",
    "true_curvature_corrected_distances_r = zeros(d)\n",
    "\n",
    "exact_tangent_distances_r = zeros(d)\n",
    "exact_distances_r= zeros(d)\n",
    "\n",
    "for rank in 1:d\n",
    "    naive_log_q_data_r = Symmetric.([sum([nR_q[rank][i] * nU[rank][k,i] for i in 1:rank]) for k in 1:n])\n",
    "    curvature_corrected_log_q_data_r = Symmetric.([sum([ccR_q[rank][i] * ccU[rank][k,i] for i in 1:rank]) for k in 1:n])\n",
    "    exact_log_q_data_r = Symmetric.([sum([eR_q[rank][i] * eU[rank][k,i] for i in 1:rank]) for k in 1:n])\n",
    "    \n",
    "    # expoentiate back\n",
    "    naive_data_r = exp.(Ref(M), Ref(q), naive_log_q_data_r)\n",
    "    curvature_corrected_data_r = exp.(Ref(M), Ref(q), curvature_corrected_log_q_data_r)\n",
    "    exact_data_r = exp.(Ref(M), Ref(q), exact_log_q_data_r)\n",
    "\n",
    "\n",
    "    # compute relative tangent space error\n",
    "    naive_tangent_distances_r[rank] = sum(norm.(Ref(M), Ref(q),  log_q_data - naive_log_q_data_r).^2) / ref_distance\n",
    "    curvature_corrected_tangent_distances_r[rank] = sum(norm.(Ref(M), Ref(q),  log_q_data - curvature_corrected_log_q_data_r).^2) / ref_distance\n",
    "    exact_tangent_distances_r[rank] = sum(norm.(Ref(M), Ref(q),  log_q_data - exact_log_q_data_r).^2) / ref_distance\n",
    "\n",
    "\n",
    "    # compute relative manifold error\n",
    "    predicted_naive_distances_r[rank] = curvature_corrected_loss(M, q, data, naive_log_q_data_r)\n",
    "    true_naive_distances_r[rank] = exact_loss(M, q, data, naive_log_q_data_r)\n",
    "    predicted_curvature_corrected_distances_r[rank] = curvature_corrected_loss(M, q, data, curvature_corrected_log_q_data_r)\n",
    "    true_curvature_corrected_distances_r[rank] = exact_loss(M, q, data, curvature_corrected_log_q_data_r)\n",
    "    exact_distances_r[rank] = exact_loss(M, q, data, exact_log_q_data_r)\n",
    "    \n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/wdiepeveen/Documents/PhD/Projects/8 - Manifold-valued tensor decomposition/src/manifold-valued-tensors/experiments/1D/P3/results/artificial1D_exact_iterate_loss.png\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want plots with (1) the lower bound error, (2) the actually uncorrected manifold error and (3) the corrected manifold error\n",
    "plot(1:d, [naive_tangent_distances_r, true_naive_distances_r, true_curvature_corrected_distances_r, exact_distances_r], label = [\"theoretical lower bound\" \"naive\" \"curvature corrected\" \"exact\"], ylims=(0,1), xlims=(1,d),xaxis=(\"approximation rank\"), yaxis=(L\"$\\varepsilon_{rel}$\"))\n",
    "savefig(\"results/artificial1D_errors_by_rank.png\")\n",
    "plot(1:d, [naive_tangent_distances_r .+ 1e-16, true_naive_distances_r .+ 1e-16, true_curvature_corrected_distances_r .+ 1e-16, exact_distances_r .+ 1e-16], label = [\"theoretical lower bound\" \"naive\" \"curvature corrected\" \"exact\"], ylims=(1e-16,1), xlims=(1,d), xaxis=(\"approximation rank\"), yaxis=(L\"$\\varepsilon_{rel}$\", :log), legend=:bottomleft)\n",
    "savefig(\"results/artificial1D_logerrors_by_rank.png\")\n",
    "for i in 1:d-1\n",
    "    if i == 1\n",
    "        plot(1:length(eCosts[1]), eCosts[1], label = \"rank 1\", ylims=(1e-4,1), yaxis=(L\"$\\varepsilon_{rel}$\", :log))\n",
    "    else\n",
    "        plot!(1:length(eCosts[i]), eCosts[i], label = \"rank $(i)\", ylims=(1e-4,1), yaxis=(L\"$\\varepsilon_{rel}$\", :log))\n",
    "    end\n",
    "end\n",
    "savefig(\"results/artificial1D_exact_iterate_loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"/Users/wdiepeveen/Documents/PhD/Projects/8 - Manifold-valued tensor decomposition/src/manifold-valued-tensors/experiments/1D/P3/results/artificial1D_logdiscrepancy_by_rank.png\""
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# It would be nice to also have a plot that tells us something about the error in predicting the manifold loss (using CCL) and the actual loss \n",
    "# (1) for the naive approach (2) for the curvature corrected approach\n",
    "plot(1:d, [(predicted_naive_distances_r .+ 1e-16) ./ (true_naive_distances_r .+ 1e-16), (predicted_curvature_corrected_distances_r .+ 1e-16) ./ (true_curvature_corrected_distances_r .+ 1e-16)], label = [\"discrepancy in initialisation\" \"discrepancy in solutions\"], xlims=(1,d),xaxis=(\"approximation rank\"), yaxis=(L\"$\\delta_{rel}$\"))\n",
    "savefig(\"results/artificial1D_discrepancy_by_rank.png\")\n",
    "plot(1:d, [(predicted_naive_distances_r .+ 1e-16) ./ (true_naive_distances_r .+ 1e-16), (predicted_curvature_corrected_distances_r .+ 1e-16) ./ (true_curvature_corrected_distances_r .+ 1e-16)], label = [\"discrepancy in initialisation\" \"discrepancy in solutions\"], xlims=(1,d), xaxis=(\"approximation rank\"), yaxis=(L\"$\\delta_{rel}$\", :log), legend=:bottomleft)\n",
    "savefig(\"results/artificial1D_logdiscrepancy_by_rank.png\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark different methods ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = @benchmark naive_low_rank_approximation(M, q, data, 2)\n",
    "mean(t).time\n",
    "std(t).time\n",
    "# TODO also do the benchmarking in here similarly as run above | also do this for 3 different step sizes for exact | if benchmark=true\n",
    "@benchmark exact_low_rank_approximation(M, q, data, 2; stepsize=1/10000, max_iter=50) \n",
    "@benchmark curvature_corrected_low_rank_approximation(M, q, data, 2) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
